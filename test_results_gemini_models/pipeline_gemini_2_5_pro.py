"""
Generated by: gemini-2.5-pro
Timestamp: 2025-11-13T12:33:50.892158
Generation time: 19.13s
"""

def build_full_pipeline():
    """
    Builds a complete scikit-learn machine learning pipeline for the breast cancer dataset.

    The pipeline consists of three main stages:
    1. Preprocessing: Handles missing values and scales the features.
    2. Feature Engineering: Reduces dimensionality using Principal Component Analysis (PCA).
    3. Model: A Logistic Regression classifier for binary classification.

    Returns:
        sklearn.pipeline.Pipeline: A fully constructed scikit-learn pipeline object.
    """
    # Import necessary libraries within the function
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.impute import SimpleImputer
    from sklearn.decomposition import PCA
    from sklearn.linear_model import LogisticRegression

    # --- Step 1: Preprocessor ---
    # This is a nested pipeline to handle data cleaning and scaling.
    # The breast cancer dataset has 30 numerical features with varying scales.
    # For instance, 'mean area' is orders of magnitude larger than 'mean smoothness'.
    # Scaling is crucial for distance-based or gradient-based algorithms like PCA and Logistic Regression.
    preprocessor = Pipeline(steps=[
        (
            'imputer',
            # Although the scikit-learn breast_cancer dataset has no missing values,
            # this step makes the pipeline robust for real-world data that might.
            # 'mean' strategy is a simple and effective choice for numerical features.
            SimpleImputer(strategy='mean')
        ),
        (
            'scaler',
            # StandardScaler standardizes features by removing the mean and scaling to unit variance.
            # This ensures all features contribute equally to the model's performance,
            # preventing features with larger scales from dominating the learning process.
            StandardScaler()
        )
    ])

    # --- Step 2: Feature Engineering ---
    # This step focuses on dimensionality reduction.
    # The dataset has 30 features, some of which may be correlated (e.g., radius, perimeter, area).
    # PCA reduces the number of features while retaining most of the original information (variance).
    feature_engineering = Pipeline(steps=[
        (
            'pca',
            # We are reducing the 30 features down to 10 principal components.
            # This helps to reduce model complexity, potentially speed up training,
            # and can sometimes improve performance by filtering out noise.
            # The choice of n_components=10 is a heuristic to capture significant variance
            # without losing too much information.
            # 'random_state=42' ensures that the PCA results are reproducible.
            PCA(n_components=10, random_state=42)
        )
    ])

    # --- Step 3: Model ---
    # The final step is the classification model.
    # Logistic Regression is chosen as it's a simple, interpretable, and powerful baseline
    # model for binary classification tasks like this one. It works very well on
    # scaled data and is computationally efficient.
    model = LogisticRegression(
        # 'liblinear' is a good solver for smaller datasets and binary classification.
        solver='liblinear',

        # C=1.0 is the inverse of regularization strength. A smaller C means stronger
        # regularization. The default of 1.0 is a good starting point that provides
        # a balance between fitting the training data and avoiding overfitting.
        C=1.0,

        # 'random_state=42' ensures reproducibility of the model's training process.
        random_state=42
    )

    # --- Combine all steps into a single, final pipeline ---
    # The final pipeline chains all the previous steps together. When fit on data,
    # it will sequentially apply the imputer, scaler, PCA, and finally train the
    # Logistic Regression model on the transformed data.
    full_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('feature_engineering', feature_engineering),
        ('model', model)
    ])

    return full_pipeline