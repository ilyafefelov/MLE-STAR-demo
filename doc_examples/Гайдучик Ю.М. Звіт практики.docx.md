**ИВАТНЕ АКЦІОНЕРНЕ ТОВАРИСТВО**  
**ВИЩИЙ НАВЧАЛЬНИЙ ЗАКЛАД**  
**"МІЖРЕГІОНАЛЬНА АКАДЕМІЯ УПРАВЛІННЯ ПЕРСОНАЛОМ"**  
**ІНСТИТУТ КОМП’ЮТЕРНО-ІНФОРМАЦІЙНИХ ТЕХНОЛОГІЙ**

**ЗВІТ**

**Про виконання програми переддипломної практики**

Гайдучк Юрій Миколайович  
Шифр групи: ІК-9-24-М1ІПЗ (1.6д)-ІТ  
Спеціальність "Інженерія програмного забезпечення"  
Кваліфікаційний рівень "Магістр"  
База практики: ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН»  
Міжрегіональна академія управління персоналом  
Інститут комп'ютерно-інформаційних технологій

| Керівник практики від бази практики | Керівник практики від навчального закладу |
| :---- | :---- |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ | \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |
|  | професор, д.т.н. |
|  | Кавун С.В. |

 Звіт захищений   
"             " \_\_\_\_\_\_\_\_\_\_\_\_ 2025 року 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   
	  
	(підпис) 

Київ 2025

[**Вступ	4**](#вступ)

[**Розділ 1\. Загальні відомості про практику та аналіз предметної області	5**](#розділ-1.-загальні-відомості-про-практику-та-аналіз-предметної-області)

[1.2. Мета та завдання практики	5](#1.2.-мета-та-завдання-практики)

[1.3. Об'єкт і предмет практики	7](#1.3.-об'єкт-і-предмет-практики)

[1.4. Актуальність і практична значущість	7](#1.4.-актуальність-і-практична-значущість)

[1.5. Коротка характеристика бази практики	8](#1.5.-коротка-характеристика-бази-практики)

[1.6. Опис технологічного контексту (стек)	8](#1.6.-опис-технологічного-контексту-\(стек\))

[1.7. Організація та охорона праці, інформаційна безпека	9](#1.7.-організація-та-охорона-праці,-інформаційна-безпека)

[**Розділ 2\. Проєктування архітектури багатофакторної інформаційної системи	10**](#розділ-2.-проєктування-архітектури-багатофакторної-інформаційної-системи)

[2.1. Аналіз вимог та постановка завдань	10](#2.1.-аналіз-вимог-та-постановка-завдань)

[2.2. Проєктування архітектури збору та підготовки даних	12](#2.2.-проєктування-архітектури-збору-та-підготовки-даних)

[2.3. Проєктування багатофакторної моделі ознак	12](#2.3.-проєктування-багатофакторної-моделі-ознак)

[**Розділ 3\. Етапи розробки та валідації прототипу системи	14**](#розділ-3.-етапи-розробки-та-валідації-прототипу-системи)

[3.1. Розробка та налаштування модулів збору текстових даних	14](#3.1.-розробка-та-налаштування-модулів-збору-текстових-даних)

[3.2. Реалізація конвеєра обробки та аналізу (ML Pipeline)	14](#3.2.-реалізація-конвеєра-обробки-та-аналізу-\(ml-pipeline\))

[3.3. Тестування системи та усунення помилок	15](#3.3.-тестування-системи-та-усунення-помилок)

[3.4. Підготовка звітності та документації	16](#3.4.-підготовка-звітності-та-документації)

[**Загальні висновки	17**](#загальні-висновки)

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# **Вступ** {#вступ}

Цей технічний звіт підсумовує результати, отримані під час проходження переддипломної практики студентом Гайдучиком Юрієм Миколайовичем. Практика проходила на базі провідної української технологічної компанії ТОВ "ГОУ АЙТИ ЕДЬЮКЕЙШН" у період з 01 вересня 2025 року по 09 листопада 2025 року.     
Вибір ТОВ "ГОУ АЙТИ ЕДЬЮКЕЙШН" як бази практики був зумовлений високим рівнем інженерної культури компанії та її фокусом на розробці власних високотехнологічних платформ. Підприємство надало середовище для вирішення складних науково-дослідних завдань, що підтверджується календарним планом практики, який включав такі ключові етапи, як "Проєктування архітектури багатофакторної інформаційної системи" та "Розробка моделей машинного навчання та AI для аналізу текстів".     
Робота в рамках практики була зосереджена на одній з найбільш гострих та динамічних проблем сучасного інформаційного простору — виявленні скоординованої неавтентичної поведінки (Coordinated Inauthentic Behavior, CIB). Це явище, кероване прихованими групами акаунтів (що можуть включати як ботів, так і людей), становить пряму загрозу суспільній довірі та інформаційній безпеці. Шляхом масового поширення дезінформації, пропаганди та маніпулятивного контенту, ці мережі намагаються впливати на суспільну думку, особливо на таких вразливих платформах, як Facebook та TikTok, що становлять особливий інтерес для українського інфопростору.   
Особливий акцент було зроблено на застосуванні практичного технологічного стеку, що включав: Python як основну мову розробки; Prefect для оркестрації конвеєрів даних (data pipelines); PostgreSQL для зберігання зібраних даних; та сучасні бібліотеки машинного навчання, зокрема Hugging Face Transformers (для роботи з BERT) та HDBSCAN (для кластеризації).     
Таким чином практика дозволила не лише теоретично дослідити ці технології а й застосувати отримані знання під час роботи на маультифакторною системою інтелектуального аналізу тексту в соцмережах

# Розділ 1\. Загальні відомості про практику та аналіз предметної області {#розділ-1.-загальні-відомості-про-практику-та-аналіз-предметної-області}

**1.1. Вступ та підстави проходження**  
В рамках навчального процесу за освітньо-професійною програмою магістратури в ПрАТ «ВНЗ «МАУП», переддипломна практика є невід'ємною та обов'язковою складовою для студентів спеціальності «Інженерія програмного забезпечення». Мета практики полягає у закріпленні та поглибленні теоретичної бази, формуванні практичних інженерних навичок, апробації досліджуваних методів та підготовці до виконання фінальної кваліфікаційної роботи магістра.     
Практика проходила на базі ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН» у період з 01.09.2025 по 09.11.2025. Тематика практики безпосередньо відноситься до теми магістерської роботи, що присвячена розробці багатофакторної інформаційної системи для інтелектуального аналізу текстових даних, зокрема для виявлення прихованих патернів та неавтентичної поведінки у соціальних мережах.   

## **1.2. Мета та завдання практики** {#1.2.-мета-та-завдання-практики}

Метою практики є формування цілісних інженерних компетентностей для побудови та валідації прототипу системи інтелектуального аналізу даних. Це включає повний цикл робіт: від аналізу предметної області та існуючих підходів до проектування архітектури, розробки програмних модулів, реалізації конвеєра машинного навчання та валідації отриманих результатів.  
Для досягнення поставленої мети було визначено такі основні завдання, що відповідають календарному плану  та були згруповані за етапами інженерного процесу:   

1. Аналітичні:  
   1. Ознайомлення зі структурою підприємства ТОВ "ГОУ АЙТИ ЕДЬЮКЕЙШН", його корпоративною культурою та середовищем розробки.     
   2. Проходження інструктажу з техніки безпеки та охорони праці.     
   3. Виконання аналізу вимог та постановка завдань для розробки прототипу інформаційної системи, здатної аналізувати текстові дані з соціальних мереж.     
2. Проєктні:  
   1. Проектування архітектури багатофакторної інформаційної системи, що включає модулі збору, обробки та аналізу даних.     
   2. Проектування багатофакторної моделі ознак, здатної фіксувати семантичні, тематичні та стилістичні аспекти текстових даних.     
3. Інженерні (Розробка):  
   1. Розробка та налаштування програмних модулів збору текстових даних з використанням сучасних інструментів оркестрації та видобутку.     
   2. Розробка та реалізація моделей машинного навчання та ШІ для інтелектуального аналізу текстів, включаючи генерацію ембедингів та кластеризацію.     
4. Тестування та Валідація:  
   1. Тестування всієї системи, валідація роботи конвеєра машинного навчання, аналіз та усунення виявлених помилок.     
5. Звітні:  
   1. Підготовка фінальної звітності, технічної документації до прототипу та формулювання висновків щодо ефективності обраної архітектури.   

## 

## **1.3. Об'єкт і предмет практики** {#1.3.-об'єкт-і-предмет-практики}

Об'єкт: Процес розробки, розгортання та валідації програмних систем для інтелектуального аналізу неструктурованих текстових даних у хмарно-орієнтованих середовищах.  
Предмет: Методи та інструменти проектування багатофакторних моделей ознак, архітектур збору даних (data pipelines), застосування сучасних моделей обробки природної мови (NLP), зокрема трансформерів (BERT), та методів кластеризації без вчителя (UMAP, HDBSCAN) для виявлення скоординованої неавтентичної поведінки.

## **1.4. Актуальність і практична значущість** {#1.4.-актуальність-і-практична-значущість}

Актуальність роботи зумовлена експоненціальним зростанням обсягів неструктурованих текстових даних у соціальних мережах. Водночас, ці платформи стали середовищем для поширення автоматизованої та координованої неавтентичної поведінки (Coordinated Inauthentic Behavior, CIB), включаючи діяльність ботів, поширення дезінформації та маніпулятивних кампаній.3 Традиційні методи аналізу, що спираються лише на один фактор (наприклад, семантику), є недостатніми для виявлення цих складних загроз.  
Практична значущість роботи для бази практики ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН» полягає у розробці прототипу системи, здатної вирішувати прямі бізнес-задачі. Як провідна EdTech-компанія з активною присутністю в Інтернеті, GoIT стикається з необхідністю аналізувати тисячі коментарів та відгуків. Створення інструменту, що автоматично виявляє аномалії, "шум" від ботів та скоординовані кампанії (наприклад, "рейди" хейтерів або штучне "накручування" позитивних відгуків), дозволяє отримати очищену, достовірну картину зворотного зв'язку, захистити репутацію бренду та приймати управлінські рішення на основі якісних даних.

## **1.5. Коротка характеристика бази практики** {#1.5.-коротка-характеристика-бази-практики}

Базою для проходження практики було обрано ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН» — лідера українського EdTech-ринку в сегменті IT-освіти. Це не просто розробник контенту, а повноцінна технологічна організація, що створює та підтримує власні складні навчальні платформи та рішення.  
Рівень інженерної культури в компанії дуже високий, з чітким фокусом на інновації та сучасні технології. Стандарти роботи компанії включають:  
Сучасний підхід до розробки: Акцент на якості коду, архітектурних рішеннях, а також передових практиках front-end та back-end.  
Надійна інфраструктура: Використання DevOps-підходів та хмарних (cloud-native) технологій для забезпечення стабільності та масштабованості сервісів.  
Таке технологічне підґрунтя створює реалістичне інженерне середовище. Це середовище виявилося оптимальним для виконання завдань практики, оскільки дозволило на практиці пройти весь цикл розробки прототипу системи інтелектуального аналізу даних: від аналізу вимог та проектування до безпосередньої розробки та тестування.

## **1.6. Опис технологічного контексту (стек)** {#1.6.-опис-технологічного-контексту-(стек)}

У рамках практики для реалізації поставлених завдань було використано сучасний стек технологій, орієнтований на задачі Data Science та ML Engineering:

* Мова програмування: Python 3.10 (як стандарт індустрії для машинного навчання).  
* Оркестрація (Data Pipeline): Фреймворк Prefect, що дозволяє будувати, планувати та моніторити відмовостійкі конвеєри збору та обробки даних.  
* Видобуток даних: Використання сервісу Apify для вирішення складних задач веб\-видобутку з динамічних платформ, таких як Facebook та TikTok.  
* Зберігання даних: Реляційна СУБД PostgreSQL, обрана для надійного зберігання "сирих" та структурованих текстових даних.  
* ML / NLP:  
  * Бібліотека Hugging Face Transformers для доступу та використання трансформерних моделей (зокрема, bert-base-multilingual-cased та xlm-roberta-large-xnli).  
  * Бібліотеки scikit-learn, UMAP-learn та HDBSCAN для реалізації конвеєра кластеризації (інженерія ознак, зниження розмірності та кластеризація).

## **1.7. Організація та охорона праці, інформаційна безпека** {#1.7.-організація-та-охорона-праці,-інформаційна-безпека}

Під час практики було дотримано всіх правил внутрішнього розпорядку підприємства ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН». На початку робіт (01.09.2025) було пройдено обов'язковий інструктаж з техніки безпеки та протипожежної безпеки.  
Вся робота з корпоративними ресурсами, даними та програмним кодом велася з суворим дотриманням політик інформаційної безпеки компанії, що є критично важливим при роботі з аналізом даних та розробкою програмного забезпечення.

# Розділ 2\. Проєктування архітектури багатофакторної інформаційної системи {#розділ-2.-проєктування-архітектури-багатофакторної-інформаційної-системи}

## **2.1. Аналіз вимог та постановка завдань** {#2.1.-аналіз-вимог-та-постановка-завдань}

Робота над проєктом розпочалася з ключового аналітичного етапу (відповідно до календарного плану, 01.09.2025 – 12.09.2025). На цьому етапі було проведено аналіз предметної області та сформульовано низку функціональних та нефункціональних вимог до майбутнього прототипу системи.  
Функціональні вимоги (FR) визначають конкретні операції, які система повинна виконувати для реалізації аналітичного конвеєра:

* FR-1: Імпорт даних. Система повинна забезпечувати завантаження "сирих" даних про дописи та коментарі із зовнішнього сховища (наприклад, PostgreSQL).     
* FR-2: Фільтрація корпусу. Система повинна надавати механізми фільтрації вхідних коментарів за конфігурованими критеріями якості (наприклад, довжина тексту, вміст не-текстових символів).     
* FR-3: Генерація семантичних ознак. Система повинна генерувати високорозмірні семантичні ембединги для кожного коментаря з використанням трансформерної моделі, здатної обробляти багатомовний контент (bert-base-multilingual-cased).     
* FR-4: Генерація тематичних ознак. Система повинна автоматично розраховувати набір тематичних категорій для контенту кожного унікального автора за допомогою Zero-Shot моделі (xlm-roberta-large-xnli).     
* FR-5: Генерація стилістичних ознак. Система повинна розраховувати набір статистичних та стилістичних метрик (наприклад, коефіцієнти дублювання, лексична різноманітність) для кожного унікального автора.     
* FR-6: Відбір та оптимізація ознак. Система повинна реалізовувати процес відбору ознак (feature selection) для зменшення розмірності та видалення корельованих метрик.  
* FR-7: Об'єднання ознак (Feature Fusion). Система повинна коректно об'єднувати (конкатенувати) вектори ознак, згенеровані на різних рівнях (коментар, автор), у єдиний фінальний вектор.     
* FR-8: Кластеризація. Система повинна виконувати кластеризацію без попередньо визначеної кількості кластерів (k) та підтримувати ефективне зниження розмірності.   
* FR-9: Виведення результатів. Система повинна зберігати фінальний результат у вигляді мітки кластера (включно з міткою шуму \-1 для некласифікованих елементів) для кожного вхідного коментаря.

Нефункціональні вимоги (NFR) визначають якісні атрибути, що є критичними для систем машинного навчання:

* NFR-1: Стійкість до шуму (Noise Resilience). Система повинна бути здатною ефективно обробляти "зашумлені", неідеальні дані реальних соціальних мереж.  
* NFR-2: Інтерпретованість (Interpretability). Результати роботи системи (кластери) мають бути придатними для якісного аналізу та інтерпретації людиною.    
* NFR-3: Масштабованість (Scalability). Архітектура має бути здатною до масштабування на більші набори даних (наприклад, сотні тисяч коментарів).   
* NFR-4: Розширюваність (Extensibility). Архітектура повинна дозволяти легке додавання нових типів ознак (наприклад, з метаданих профілю) без повної перебудови моделі.   
* NFR-5: Відтворюваність (Reproducibility). Аналітичний конвеєр має забезпечувати відтворюваність результатів при однакових вхідних даних та гіперпараметрах. 

## **2.2. Проєктування архітектури збору та підготовки даних** {#2.2.-проєктування-архітектури-збору-та-підготовки-даних}

Для задоволення вимог FR-1 (Імпорт даних) та NFR-3 (Масштабованість), а також для забезпечення надійності процесу, було спроєктовано модульну та відмовостійку архітектуру збору даних. Ця архітектура, що відповідає сучасним принципам інженерії даних, складається з трьох ключових компонентів:

1. Рівень оркестрації (Orchestration): Було прийнято рішення використовувати фреймворк Prefect. Це дозволяє автоматизувати, планувати та моніторити виконання всього конвеєра збору даних. Prefect керує розкладом, обробляє можливі збої та забезпечує надійне послідовне виконання завдань.2  
2. Рівень видобутку (Extraction): Оскільки API соціальних мереж (Facebook, TikTok) мають суттєві обмеження, було спроєктовано використання сервісу Apify як проміжного шару. Це рішення дозволяє делегувати складні інженерні задачі (обхід механізмів захисту, робота з динамічним контентом) спеціалізованому інструменту.  
3. Рівень зберігання (Storage): Усі зібрані "сирі" дані (тексти постів та коментарів) було вирішено структурувати та зберігати у реляційній базі даних PostgreSQL. Такий вибір забезпечує надійне зберігання та гнучкість для подальших SQL-запитів та агрегації на етапі аналізу.

## **2.3. Проєктування багатофакторної моделі ознак** {#2.3.-проєктування-багатофакторної-моделі-ознак}

Це ядро спроєктованого прототипу. На основі аналізу, проведеного на першому етапі (та теоретичних основ, закладених у Розділі 1 магістерської роботи), було виявлено, що одновимірні підходи (що аналізують, наприклад, лише семантику тексту) є недостатніми для надійного виявлення CIB.  
Тому було спроєктовано інноваційну трьохрівневу багатофакторну модель ознак, яка паралельно аналізує три різні виміри поведінки користувачів та безпосередньо реалізує вимоги NFR-2 (Інтерпретованість) та NFR-4 (Розширюваність) :

1. Рівень 1: Семантика ("Що сказано?"):  
   1. Реалізує: FR-3.  
   2. Проєктне рішення: Використання трансформерної моделі bert-base-multilingual-cased для отримання семантичних ембедингів (векторів) для кожного коментаря. Вибір multilingual-моделі є критичним для обробки гібридного українського інфопростору, де змішуються мови.  
2. Рівень 2: Намір / Тематика ("Яка мета?"):  
   1. Реалізує: FR-4, NFR-4.  
   2. Проєктне рішення: Використання моделі Zero-Shot Classification (на базі xlm-roberta-large-xnli) для класифікації контенту автора за набором визначених тем (наприклад, "пропаганда", "спам", "токсичність"). Цей підхід забезпечує виняткову розширюваність (NFR-4), оскільки дозволяє додавати нові теми для аналізу без перенавчання моделі.2  
3. Рівень 3: Стиль ("Як сказано?"):  
   1. Реалізує: FR-5, NFR-2.  
   2. Проєктне рішення: Розрахунок набору прозорих статистичних та стилістичних метрик (наприклад, exact\_duplicate\_ratio, fuzzy\_duplicate\_ratio, лексична різноманітність). Цей рівень є ключовим для інтерпретованості (NFR-2): якщо кластер має високі показники "копіпасти", аналітик отримує пряме, зрозуміле пояснення причини групування.

Таке трьохрівневе проектування дозволяє системі фіксувати складні патерни, де, наприклад, семантично різні коментарі можуть належати до однієї кампанії, оскільки вони мають спільний намір (Рівень 2\) або однаковий стилістичний "відбиток" (Рівень 3).

# Розділ 3\. Етапи розробки та валідації прототипу системи {#розділ-3.-етапи-розробки-та-валідації-прототипу-системи}

## **3.1. Розробка та налаштування модулів збору текстових даних** {#3.1.-розробка-та-налаштування-модулів-збору-текстових-даних}

Цей етап (відповідно до Завдання 5 календарного плану) був присвячений практичній реалізації архітектури, спроєктованої у Розділі 2.2.1 Протягом практики було розроблено програмні скрипти на Python, які інкапсулювали логіку взаємодії з API сервісу Apify для видобутку даних з цільових соціальних мереж.  
Для забезпечення автоматизації та надійності (NFR-1, NFR-3), ці скрипти були інтегровані у фреймворк оркестрації Prefect. Було налаштовано конвеєри (flows), що дозволило автоматично запускати завдання збору даних за розкладом, керувати залежностями між завданнями та обробляти можливі збої. Зібрані "сирі" дані (тексти коментарів та їх метадані) успішно парсилися та зберігалися у визначеній структурі в базі даних PostgreSQL, підготувавши основу для наступного етапу аналізу.

## **3.2. Реалізація конвеєра обробки та аналізу (ML Pipeline)** {#3.2.-реалізація-конвеєра-обробки-та-аналізу-(ml-pipeline)}

На цьому етапі (Завдання 6\) була виконана практична реалізація багатофакторної моделі, спроєктованої у Розділі 2.3.1 Було розроблено комплексний конвеєр машинного навчання (ML Pipeline) на Python, який виконував наступні кроки:

1. Побудова єдиного простору ознак: Написання коду, який завантажував дані з PostgreSQL та паралельно генерував три набори ознак (семантичні BERT, тематичні Zero-Shot та стилістичні) для кожного коментаря.  
2. Інженерія ознак (Feature Engineering): Реалізація процесу об'єднання (конкатенації) трьох векторів в єдиний. Для збалансування їхнього впливу було застосовано вагові коефіцієнти. Експериментально було визначено, що стилістичні ознаки (Рівень 3\) є надзвичайно сильними індикаторами CIB (наприклад, копіпаста), тому їхня вага у фінальному векторі була підвищена.  
3. Зниження розмірності: Отриманий високорозмірний простір ознак (789 вимірів) є обчислювально складним для кластеризації. Для вирішення цієї проблеми було застосовано нелінійний метод UMAP (Uniform Manifold Approximation and Projection). Це дозволило ефективно стиснути простір до значно меншої кількості вимірів (напр., 15), зберігши при цьому суттєву топологічну структуру даних. Цей крок є критичним для забезпечення масштабованості (NFR-3).  
4. Кластеризація: На отриманий 15-вимірний простір було застосовано алгоритм HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise). Цей алгоритм було обрано свідомо: по-перше, він не вимагає заздалегідь вказувати очікувану кількість кластерів (k) (FR-8); по-друге, він чудово реалізує вимогу NFR-1 (Стійкість до шуму), оскільки автоматично ідентифікує та маркує викиди (outliers) як "шум" (мітка \-1), не "забруднюючи" ними релевантні кластери.

## **3.3. Тестування системи та усунення помилок** {#3.3.-тестування-системи-та-усунення-помилок}

Відповідно до календарного плану, значна частина практики (з 22.09.25 по 09.11.25) була присвячена тестуванню, валідації та ітеративному покращенню розробленого прототипу.  
Тестування прототипу проводилося на контрольному наборі даних, зібраному на попередніх етапах. Ефективність розробленої багатофакторної моделі порівнювалася з базовим (baseline) підходом, таким як кластеризація виключно на семантичних ознаках BERT.  
Результати валідації продемонстрували значні переваги запропонованої багатофакторної архітектури. Прототип зміг ідентифікувати щільні, логічно зв'язані кластери, які чітко інтерпретувалися (NFR-2) як скоординована неавтентична поведінка (наприклад, кластери, що об'єднували коментарі з високим показником дублікатів, або кластери, об'єднані спільною пропагандистською тематикою).  
Найважливішим є те, що багатофакторний підхід, особливо завдяки валідації кроків інженерії ознак та вибору алгоритму HDBSCAN, дозволив радикально значно покращити якість кластеризації порівняно з "наївною" базовою моделлю, очевидна коориднована активність знанчо рідше потрапляє в “шум” та більш шільно і якісно кластеризується. Це підтвердило, що обрана архітектура моделі ознак є валідною та ефективно виявляє приховані патерни у зашумлених реальних даних.

## **3.4. Підготовка звітності та документації** {#3.4.-підготовка-звітності-та-документації}

Заключний етап практики (з 29.09.25 по 09.11.25) був присвячений систематизації отриманих результатів. Було проведено документування розробленого програмного коду, описано архітектуру прототипу та підготовлено технічну документацію. Також було сформульовано висновки щодо ефективності обраного стеку та архітектури і підготовлено даний звіт про проходження переддипломної практики.

# Загальні висновки {#загальні-висновки}

Під час проходження переддипломної практики на базі ТОВ «ГОУ АЙТИ ЕДЬЮКЕЙШН» були повністю виконані всі поставлені завдання, що визначені календарним планом.  
Було здобуто цінні практичні навички та інженерні компетенції у повному циклі розробки та валідації прототипу системи інтелектуального аналізу даних. Зокрема, було виконано наступні ключові етапи:  
Проведено аналіз предметної області, виявлено обмеження існуючих одновимірних підходів та сформульовано функціональні й нефункціональні вимоги до майбутньої системи.2  
Спроектовано відмовостійку архітектуру збору даних (з використанням Prefect, Apify, PostgreSQL) та інноваційну багатофакторну модель ознак (Семантика-Тематика-Стиль).2  
Розроблено програмні модулі для збору, підготовки та структурування текстових даних з соціальних мереж (Facebook, TikTok).  
Реалізовано та апробовано комплексний конвеєр машинного навчання, що включає генерацію ознак (BERT, Zero-Shot), зважування, нелінійне зниження розмірності (UMAP) та густинну кластеризацію (HDBSCAN).2  
Проведено тестування та валідацію прототипу, що підтвердило високу ефективність обраного багатофакторного підходу у виявленні інтерпретованих кластерів та значному зниженні рівня "шуму" порівняно з базовими моделями.  
Обраний стек технологій (Python, Prefect, Transformers, HDBSCAN) довів свою високу гнучкість та ефективність для вирішення складних завдань інтелектуального аналізу неструктурованих текстових даних. Здобуті навички та результати, отримані під час роботи над цим практичним проєктом, ляжуть в основу практичної частини магістерської кваліфікаційної роботи.