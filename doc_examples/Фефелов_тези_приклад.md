**УДК 004.852:519.87**  
*Інформаційні технології та машинне навчання*

**Фефелов Ілля Олександрович**, магістрант; **Чернишов Дмитро Олександрович**, к.т.н., доцент  
**АБЛЯЦІЙНИЙ АНАЛІЗ AI-ЗГЕНЕРОВАНИХ ML-КОНВЕЄРІВ НА ОСНОВІ GEMINI API**

*Міжрегіональна академія управління персоналом, м. Київ*

Активне впровадження генеративних моделей (LLM) у процес побудови ML-конвеєрів створює попит на формальні методи перевірки якості автоматично згенерованих рішень. У роботі досліджується, як окремі компоненти пайплайна, сформованого моделлю **Gemini 2.5 Flash Lite** через офіційний SDK, впливають на точність двокласової та багатокласової класифікації. Наукова новизна полягає в першому систематичному ablation-дослідженні LLM-згенерованих конвеєрів: зберігається повний код, автоматично перебудовується модуль `mle_star_generated_pipeline.py`, а результати порівнюються зі статистичними критеріями (ANOVA, t-test із поправкою Бонферроні, оцінка ефекту Cohen's *d*).

Методологія включає чотири еталонні датасети `sklearn` (breast_cancer, wine, digits, iris), шість конфігурацій компонентів (повний конвеєр, без масштабування, без інженерії ознак, без тюнінгу, без ансамблювання, мінімальний пайплайн) та дизайн **5×5 стратифікованого перехресного контролю** (6 конфігурацій × 25 запусків = 150 експериментів на датасет). Для кожного запуску Gemini генерує повний пайплайн (SimpleImputer → StandardScaler → PCA/PolynomialFeatures → класифікатор), після чого спеціальні скрипти `scripts/main_experiment.py` і `scripts/compare_gemini_models_on_datasets.py` автоматично вимикають окремі етапи, логують метрики (`accuracy`, macro-F1, час навчання) та будують агреговані CSV (`results_full_experiment/summary_all_datasets.csv`).

**Результати та обговорення.** Найважливіші інсайти наведено в табл. 1. Масштабування даних виявилося критичним лише для датасета wine (падіння точності на 31 відсотковий пункт), тоді як інженерія ознак (PCA/поліноміальні ознаки) у трьох з чотирьох наборів даних погіршувала якість. Мінімальний пайплайн (лише модель від Gemini) не лише зберігав точність понад 95 % на breast_cancer, а й перевищував повну конфігурацію для iris (+6.67 п.п.), що ставить під сумнів універсальність складних конвеєрів, згенерованих LLM.

**Таблиця 1 – Точність найкращих конфігурацій порівняно з базовим конвеєром**

| Датасет | Найкраща конфігурація | Accuracy, % | Δ до `full`, п.п. | Коментар |
| --- | --- | ---: | ---: | --- |
| Breast Cancer | `no_feature_engineering` | **95.61** | +3.15 | Видалення PCA зменшує шум, preprocessing залишається критичним |
| Wine | `no_feature_engineering` | **99.44** | +0.55 | Відсутність scaling → 68.33 % (−31.11 п.п.), що статистично значуще (*p* < 0.001, *d* = 2.9) |
| Digits | `no_feature_engineering` | **95.94** | +0.44 | PCA на 64 ознаках не покращує модель Gemini (SVC/RF) |
| Iris | `minimal` | **94.67** | +6.67 | Простий пайплайн краще складного через низьку розмірність та чисті дані |

Окремо оцінено три модифікації Gemini (Flash, Flash Lite, Pro). Модель **Gemini 2.5 Flash Lite** забезпечує 94.21 % середньої точності (4 датасети) за 4.07 c генерації, що у 6.6 рази швидше за Pro-версію при статистично несуттєвій різниці точності (+0.5 п.п., *p* = 0.68). Це обґрунтовує вибір Flash Lite як бази для подальшої автоматизації конвеєрів у межах дипломної практики.

**Обмеження та подальше розширення тестів.** Поточний 5×5 CV дає нам лише 150 вимірювань на датасет, тож позитивні ефекти менших компонентів просто тонуть у шумі. Потрібно жорстко збільшити кількість повторів і metric coverage (macro-F1, recall, time-to-train), інакше ми й далі не побачимо реального внеску, скажімо, поліноміальних ознак на незбалансованих даних. Так само ми ще не запускали component-wise ablation (імпутер окремо від скейлера, різні scaler'и, альтернативні PCA налаштування), хоча це прямо прописано в `docs/EXPERIMENT_PROTOCOL.md`; без цього неможливо вичленити, що саме дає приріст і де ми зрізаємо потенційний позитивний ефект. У Phase 2–4 MLE-STAR методології залишаються невиконаними завдання: немає експериментів на реальних корпоративних датасетах, не відпрацьований сценарій з іншими LLM (GPT‑4, Claude), не добиті heatmap-и ANOVA/p-value та Cohen's *d*. Усі ці прогалини обмежують узагальнюваність висновків і прямо пояснюють, чому частина гіпотез (наприклад, користь PCA на digits) не підтвердилася: ми ще не створили умови, де їхній позитивний ефект міг проявитися.

**Висновки.** (1) Масштабування та імпутація залишаються єдиними компонентами з великим ефектом (|*d*| > 0.8) у LLM-згенерованих пайплайнах; (2) інженерія ознак потребує явних критеріїв активації, бо для breast_cancer/wine/iris спричиняє деградацію; (3) комбінування генеративних моделей та класичних AutoML-технік дозволяє отримати конкурентні результати без ручних налаштувань. Подальші кроки, зафіксовані у щоденнику практики, включають візуалізацію результатів (heatmaps *p*-value/Cohen's *d*), розширення на реальні корпоративні датасети та підготовку тез до публікації в журналі МАУП.

**ПЕРЕЛІК ДЖЕРЕЛ:**
1. Borchani M. et al. *Machine Learning Engineering with Multiple Agents*. arXiv:2506.15692, 2025.
2. Google DeepMind. *Gemini 2.5 Technical Report*. 2025. https://ai.googleblog.com  
3. Фефелов І.О. *Ablation Analysis of AI-Generated ML Pipelines* (експериментальний протокол, МАУП, 2025).
