**УДК 004.852:519.87**  
*Інформаційні технології та машинне навчання*

**Фефелов Ілля Олександрович**, магістрант; **Чернишов Дмитро Олександрович**, к.т.н., доцент  
**КОМПОНЕНТНИЙ АБЛЯЦІЙНИЙ АНАЛІЗ ML-КОНВЕЄРІВ, АВТОМАТИЧНО ЗГЕНЕРОВАНИХ ЧЕРЕЗ GEMINI API**

*Міжрегіональна академія управління персоналом, м. Київ*

Активне впровадження великих мовних моделей (LLM) у процес побудови ML-конвеєрів створює попит на формальні методи оцінки внеску окремих компонентів автоматично згенерованих рішень. У роботі досліджується, як preprocessing (імпутація, масштабування), feature engineering (PCA, поліноміальні ознаки) та вибір моделі впливають на точність класифікації для пайплайнів, згенерованих через Gemini API. Спочатку порівняно три варіанти моделі (Flash, Flash Lite, Pro) за критеріями accuracy/швидкість/вартість, після чого обрано **Gemini 2.5 Flash Lite** для детального компонентного аналізу. Наукова новизна полягає в першому систематичному component-wise ablation дослідженні LLM-згенерованих конвеєрів із кількісною оцінкою contribution кожного етапу через статистичні критерії (ANOVA, t-test із поправкою Бонферроні, Cohen's *d*).

Методологія включає чотири еталонні датасети `sklearn` (breast_cancer, wine, digits, iris), шість конфігурацій компонентів (повний конвеєр, без масштабування, без інженерії ознак, без тюнінгу, без ансамблювання, мінімальний пайплайн) та дизайн **5×5 стратифікованого перехресного контролю** (6 конфігурацій × 25 запусків = 150 експериментів на датасет). Для кожного запуску Gemini генерує повний пайплайн (SimpleImputer → StandardScaler → PCA/PolynomialFeatures → класифікатор), після чого автоматизовані скрипти селективно вимикають окремі етапи, логують метрики (`accuracy`, macro-F1, час навчання) та будують агреговані CSV. Порівняння варіантів Gemini показало: **Flash Lite** досягає 94.21% середньої точності за 4.07 с генерації (у 6.6× швидше за Pro при різниці точності +0.5 п.п., *p* = 0.68), що робить його оптимальним вибором для ablation досліджень.

**Результати та обговорення.** Найважливіші інсайти наведено в табл. 1. Масштабування даних виявилося критичним лише для датасета wine (падіння точності на 31 відсотковий пункт), тоді як інженерія ознак (PCA/поліноміальні ознаки) у трьох з чотирьох наборів даних погіршувала якість. Мінімальний пайплайн (лише модель від Gemini) не лише зберігав точність понад 95 % на breast_cancer, а й перевищував повну конфігурацію для iris (+6.67 п.п.), що ставить під сумнів універсальність складних конвеєрів, згенерованих LLM.

**Таблиця 1 – Точність найкращих конфігурацій порівняно з базовим конвеєром**

| Датасет | Найкраща конфігурація | Accuracy, % | Δ до `full`, п.п. | Коментар |
| --- | --- | ---: | ---: | --- |
| Breast Cancer | `no_feature_engineering` | **95.61** | +3.15 | Видалення PCA зменшує шум, preprocessing залишається критичним |
| Wine | `no_feature_engineering` | **99.44** | +0.55 | Відсутність scaling → 68.33 % (−31.11 п.п.), що статистично значуще (*p* < 0.001, *d* = 2.9) |
| Digits | `no_feature_engineering` | **95.94** | +0.44 | PCA на 64 ознаках не покращує модель Gemini (SVC/RF) |
| Iris | `minimal` | **94.67** | +6.67 | Простий пайплайн краще складного через низьку розмірність та чисті дані |

Окремо оцінено три модифікації Gemini (Flash, Flash Lite, Pro). Модель **Gemini 2.5 Flash Lite** забезпечує 94.21% середньої точності (4 датасети) за 4.07 с генерації, що у 6.6 рази швидше за Pro-версію при статистично несуттєвій різниці точності (+0.5 п.п., *p* = 0.68). Це обґрунтовує вибір Flash Lite як оптимального trade-off точність/швидкість/вартість для детальних компонентних досліджень.

**Обмеження та перспективи.** Дослідження виконано на чотирьох benchmark датасетах sklearn з фокусом на Gemini API. Для виявлення тонких ефектів окремих компонентів (RobustScaler vs StandardScaler, оптимальний variance threshold PCA) потрібне збільшення кількості повторів CV та розширення метрик (macro-F1, recall, час навчання). Розширення на реальні корпоративні дані з дисбалансом класів та noise, порівняння з іншими LLM (GPT-4, Claude) та традиційними AutoML системами (Auto-sklearn, TPOT) становить перспективу подальших робіт.

**Висновки.** (1) Preprocessing (імпутація + масштабування) є єдиним компонентом з великим ефектом (|*d*| > 0.8), критичним для wine (−31% без scaling), опціональним для iris; (2) feature engineering (PCA, polynomial features) погіршує результати на 3/4 датасетів, потребує адаптивних критеріїв активації; (3) Gemini 2.5 Flash Lite забезпечує оптимальний trade-off для компонентних досліджень; (4) мінімальний пайплайн (без preprocessing/feature engineering) залишається конкурентним на простих, чистих даних. Результати обґрунтовують необхідність component-wise аналізу для валідації автоматично згенерованих рішень.

**ПЕРЕЛІК ДЖЕРЕЛ:**
1. Borchani M. et al. *Machine Learning Engineering with Multiple Agents*. arXiv:2506.15692, 2025.
2. Google DeepMind. *Gemini 2.5 Technical Report*. 2025. https://ai.googleblog.com  
3. Фефелов І.О. *Ablation Analysis of AI-Generated ML Pipelines* (експериментальний протокол, МАУП, 2025).

