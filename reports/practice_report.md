«Міжрегіональна Академія управління персоналом»

**ЗВІТ ПРО ПЕРЕДДИПЛОМНУ ПРАКТИКУ**

Студент: **Фефелов Ілля Олександрович**  
Спеціальність: **121 «Інженерія програмного забезпечення»**  
Курс / група: **6 / ІК‑9‑24‑М1ІПЗ (1.6д)-ІТ**  
База практики: **ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН», м. Київ**  
Термін практики: **01.09.2025 — 24.11.2025**  
Керівник від Академії: **д.т.н., професор Кавун Сергій Віталійович**  
Керівник від підприємства: **О. В. Нестеренко, керівник R&D відділу**

---

## 1. Загальна характеристика бази практики
ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН» — провідна українська EdTech-компанія, що спеціалізується на розробці та підтримці навчальних програм у галузі інформаційних технологій. На відміну від класичних освітніх закладів, компанія поєднує функції навчального центру та R&D-підрозділу: паралельно з освітніми продуктами розробляються власні платформи, інструменти для роботи з даними та експериментальні ML-рішення.

У структурі підприємства виділяється окремий напрям, пов'язаний із дослідженнями в сфері AutoML та застосування великих мовних моделей (LLM) для автоматизованої побудови конвеєрів машинного навчання. Саме в рамках цього напряму розгорнуто репозиторій `MLE-STAR-demo`, який використовувався як основна технічна база практики. Репозиторій містить приклади інтеграції з Gemini API, скрипти запуску серій експериментів, модулі статистичного аналізу та візуалізації, а також конфігурації для ablation-досліджень.

База практики забезпечила доступ до внутрішнього Git-репозиторію, середовища виконання з підтримкою GPU, системи керування експериментами та методичних матеріалів щодо використання MLE-STAR у навчальному процесі. Робота проводилася в умовах, максимально наближених до реальних задач ML Engineering: з використанням систем контролю версій, стандартизованих код-рев'ю та вимог до відтворюваності експериментів.

### 1.1 Актуальність і практична значущість теми
Актуальність теми визначається необхідністю емпіричної верифікації AutoML-рішень, згенерованих великими мовними моделями. Хоча LLM суттєво скорочують час проєктування пайплайнів (з годин до хвилин), вони часто схильні до генерації надлишкового коду. Критично важливим стає питання довіри до таких рішень та визначення мінімально необхідної конфігурації конвеєра.

У межах практики розроблено інструментарій для автоматизованого дослідження даних, що дозволяє програмно генерувати варіанти пайплайнів різної складності та виконувати їх порівняльний аналіз. Це забезпечує зниження порогу входження для проведення експериментів та дозволяє оптимізувати обчислювальні ресурси, відсіюючи неефективні компоненти (наприклад, надмірну інженерію ознак) ще на етапі прототипування.

Компонентний ablation-аналіз пайплайнів, згенерованих через Gemini API у рамках підходу MLE-STAR, дозволяє отримати кількісну відповідь на ці питання. Для бази практики це має безпосередню практичну цінність: результати показують, які конфігурації (наприклад, наявність/відсутність масштабування чи інженерії ознак) доцільно використовувати в навчальних кейсах, а які варто спростити, щоб не перевантажувати студентів та інфраструктуру.

З інженерної точки зору, побудова повного циклу експериментів (генерація пайплайнів, запуск серій, статистичний аналіз, візуалізація) формує компетенції, необхідні для подальшої роботи в галузі ML Engineering та підготовки магістерської роботи. Отримані висновки можуть бути використані як база для розробки методичних матеріалів з MLE-STAR та як відправна точка для порівняння з іншими AutoML-платформами.

## 2. Мета та завдання практики
**Мета:** відпрацювати повний цикл дослідження AutoML-підходу MLE-STAR (Machine Learning Engineering Agent via Search and Targeted Refinement) із застосуванням Gemini API: від аналізу предметної області та налаштування середовища до запуску серій ablation-експериментів, статистичної інтерпретації результатів і оформлення технічної документації.

**Основні завдання:**
1. Ознайомитися зі структурою репозиторію та інфраструктурою запуску експериментів.
2. Налаштувати оточення, підключити Gemini API та автоматизувати генерацію ML-пайплайнів.
3. Провести серії ablation-експериментів на базових датасетах (iris, wine, digits, breast_cancer, california housing, diabetes, synthetic).
4. Розширити модуль статистики (`src/mle_star_ablation/stats.py`) і візуалізацій (`src/mle_star_ablation/viz.py`) для побудови теплових карт $p/t/z$-значень.
5. Перегенерувати повний набір графіків, сформувати агреговану таблицю (`results/aggregated_summary.csv`) та узагальнюючі PNG.
6. Підготувати підсумковий звіт і рекомендації щодо подальшого розвитку дослідження.

## 3. Теоретичні засади дослідження
### 3.1 AutoML, LLM та підхід MLE-STAR
AutoML-системи спрямовані на автоматизацію етапів підготовки даних, вибору моделі та налаштування гіперпараметрів. Класичні підходи (Auto-sklearn, TPOT тощо) будують конвеєри на основі пошуку в просторі моделей і трансформацій за допомогою евристик або байєсівської оптимізації. З появою великих мовних моделей (LLM) з'явилася можливість делегувати частину інженерної роботи самим моделям: описуючи задачу природною мовою, інженер отримує готовий код пайплайна, який потім можна перевірити, модифікувати та піддати ablation-аналізу.

Методологія MLE-STAR (Machine Learning Engineering Agent via Search and Targeted Refinement), запропонована Nam et al. (2025), позиціонується як інженерний шаблон, що поєднує LLM-генерацію з класичними принципами MLOps та експериментального дизайну. У оригінальній роботі MLE-STAR спочатку використовує пошук для формування початкового рішення, а потім ітеративно вдосконалює його, досліджуючи різні стратегії для конкретних ML-компонентів. Це дослідження керується ablation-аналізом, що аналізує вплив окремих блоків коду.

У межах практики було реалізовано адаптовану версію цього підходу, сфокусовану на етапі «Targeted Refinement» та «Ablation». Великомовна модель (у нашому випадку Gemini 2.5 Flash Lite) виконує роль «архітектора» конвеєра: на основі промпта вона пропонує послідовність кроків (імпутація пропусків, масштабування ознак, інженерія ознак, вибір базової моделі та її гіперпараметрів). Далі цей код інтегрується у стандартне Python-середовище, де його можна повторно запускати, фіксувати випадкові стани (random seed) і оцінювати якість на репрезентативних датасетах.

У межах практики було сфокусовано увагу на фіксованій моделі Gemini 2.5 Flash Lite, обраній на попередньому етапі порівняння варіантів (Flash, Flash Lite, Pro). Такий вибір дає змогу ізолювати вплив саме компонентів пайплайна, не змішуючи його з різницею між LLM-моделями. Саме ця ідея відповідає компонентному характеру MLE-STAR: генерація відбувається один раз, а далі інженер працює з набором варіантів конвеєра, керуючи їхньою складністю.

### 3.2 Компонентний ablation-аналіз конвеєрів
Компонентний ablation-аналіз (component-wise ablation) — це методологія, за якої з базового конвеєра послідовно вилучаються окремі компоненти, а зміна цільової метрики використовується як оцінка їхнього внеску. У випадку AutoML-пайплайнів, згенерованих Gemini, такими компонентами є:

- блоки препроцесингу (імпутація пропусків, масштабування ознак);
- блоки інженерії ознак (PCA, поліноміальні ознаки, генерація взаємодій);
- модулі оптимізації гіперпараметрів (тюнінг);
- ансамблювання моделей (стекінг, бустинг поверх базової моделі).

У репозиторії `MLE-STAR-demo` ці варіанти формалізовано як конфігурації `full`, `no_scaling`, `no_feature_engineering`, `no_tuning`, `no_ensemble`, `minimal`. Базовим вважається повний конвеєр `full`, а різниця між метриками $m_{full}$ та $m_{cfg}$ для конфігурації `cfg` інтерпретується як оцінка впливу компонента, що був вимкнений. У спрощеному вигляді внесок оцінюється як

$$\Delta m = m_{full} - m_{cfg},$$

де $m$ — середнє значення обраної метрики якості (accuracy, $R^2$ тощо). Якщо $\Delta m$ велике й стабільне на різних датасетах, то компонент є критичним; якщо ж різниця мала або негативна (вимкнення покращує результат), то компонент можна вважати опційним або навіть шкідливим для даного класу задач.

Узагальнюючи, MLE-STAR трактує LLM-згенерований конвеєр не як «чорну скриньку», а як набір модульних рішень, кожне з яких може бути включене або виключене. Компонентний ablation дозволяє перетворити інтуїтивні міркування про корисність scaling чи feature engineering на кількісні, статистично обґрунтовані висновки.

### 3.3 Статистичне обґрунтування порівнянь
Щоб відрізнити випадкові коливання метрик від справжнього ефекту компонента, використовується формальний статистичний апарат. Для кожного датасету та конфігурації запускається кілька повторів із різними випадковими станами (seed), на основі яких розраховується середнє значення метрики, стандартне відхилення та 95%-довірчий інтервал. Далі застосовуються:

- дисперсійний аналіз (ANOVA) — для перевірки гіпотези про відсутність різниці між кількома конфігураціями;
- парні t-тести для попарного порівняння `full` з іншими конфігураціями;
- коефіцієнт ефекту Cohen's $d$ для оцінки практичної значущості різниць.

Через відносно невелику кількість повторів t-статистика додатково переводиться в $z$-шкалу за формулою

$$z = \frac{t}{\sqrt{\nu}},$$

де $\nu$ — кількість ступенів вільності. Така нормалізація спрощує побудову теплових карт, де по осі X/Y відкладаються конфігурації, а в клітинках відображається $z$-значення або $p$-value. Це дозволяє наочно виділити пари конфігурацій, між якими різниця статистично значуща ($p < 0{,}05$), та швидко знаходити «нечутливі» компоненти, для яких різниця не виходить за межі статистичного шуму.

### 3.4 Теоретичні висновки
1. Препроцесинг (імпутація + масштабування) є єдиним блоком, що демонструє стабільно великий ефект ($|d| > 0.8$) для частини датасетів, зокрема wine та california housing. Це узгоджується з класичною теорією, згідно з якою коректне масштабування ознак критично важливе для моделей, чутливих до масштабу (kNN, SVM, лінійні моделі).
2. Інженерія ознак (PCA, поліноміальні перетворення) має контекстно залежний ефект: для низьковимірних та добре структурованих наборів (iris) вона часто призводить до перенавчання й погіршення якості. Для високовимірних задач її доцільність повинна перевірятися емпірично через ablation-аналіз, а не прийматися як аксіома.
3. Адаптація t-статистики до $z$-шкали та використання матриць попарних порівнянь дає можливість проводити мета-аналіз між різними датасетами, застосовуючи однакові порогові значення та візуальні шаблони (heatmap-и). Це робить результати більш інтерпретованими для інженерів та наукових керівників і підсилює довіру до висновків, сформульованих на основі експериментів.

**Гіпотеза дослідження:**
Робоча гіпотеза базується на припущенні про схильність великих мовних моделей до надмірного ускладнення рішень (over-engineering). Передбачається, що *спрощені конфігурації пайплайнів (зокрема `no_feature_engineering`) часто не поступаються або навіть перевершують повні версії (`full`) за метриками якості та стійкості*, оскільки LLM схильні генерувати надлишкові трансформації ознак, які не несуть інформаційної цінності для конкретного датасету, але збільшують ризик перенавчання. Водночас, базові етапи препроцесингу (масштабування) залишаються критичними.

## 4. Календарний план проходження практики
| № | Найменування робіт | 01.09–08.09 | 09.09–15.09 | 16.09–22.09 | 23.09–29.09 | 30.09–06.10 | 07.10–13.10 | 14.10–20.10 | 21.10–27.10 | 28.10–03.11 | 04.11–10.11 | 11.11–17.11 | 18.11–24.11 |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| 1 | Інструктажі, ознайомлення з базою та процесами | 6 | 2 |  |  |  |  |  |  |  |  |  |  |
| 2 | Вивчення методології AutoML/MLE-STAR, вимог до практики | 4 | 6 | 4 |  |  |  |  |  |  |  |  |  |
| 3 | Налаштування середовища, структури репозиторію, CI |  | 6 | 8 | 2 |  |  |  |  |  |  |  |  |
| 4 | Розробка генератора пайплайнів, інтеграція Gemini API |  |  | 6 | 6 | 4 |  |  |  |  |  |  |  |
| 5 | Постановка ablation-конфігурацій, запуск серій експериментів |  |  |  | 8 | 6 | 6 | 4 |  |  |  |  |  |
| 6 | Автоматизація збору статистики, агрегація результатів |  |  |  |  | 6 | 6 | 6 | 4 |  |  |  |  |
| 7 | Розробка нових візуалізацій (heatmaps, overview) |  |  |  |  |  | 4 | 6 | 8 | 6 | 4 |  |  |
| 8 | Повторні запуски, аналіз стабільності, документування |  |  |  |  |  |  |  | 6 | 8 | 10 | 8 | 4 |
| 9 | Підготовка тез, звіту та додатків |  |  |  |  |  |  |  |  | 4 | 8 | 10 | 12 |

Примітка: цифри відображають орієнтовну кількість годин, заплановану на кожен блок протягом відповідного тижня. План погоджено з керівниками практики.

## 5. Щоденник виконаних робіт
| Дата | Виконані роботи |
| :-- | :-- |
| 01.09 | Прибуття на базу практики, ознайомлення з внутрішнім регламентом та політиками безпеки. |
| 02.09 | Інструктажі з охорони праці, підписання календарного плану, отримання доступів до репозиторію. |
| 04.09 | Аналіз документа `docs/EXPERIMENT_PROTOCOL.md`, узгодження вибору базових датасетів. |
| 09.09 | Налаштування Python середовища за `requirements.txt`, перевірка сумісності з Windows/GPU вузлом. |
| 12.09 | Структурування директорій `results/`, заповнення `configs/task_metadata.yaml` метаданими. |
| 16.09 | Інтеграція ключів Gemini API, тестовий виклик генерації пайплайна для набору iris. |
| 19.09 | Розробка шаблонів промптів для різних режимів (full, no_scaling, minimal). |
| 23.09 | Автоматизація запуску експериментів через `scripts/run_experiment_suite.py`, параметризація seed. |
| 27.09 | Додавання логування метрик до CSV-результатів, впорядкування `generated_pipelines/`. |
| 03.10 | Перша повна серія ablation на iris/wine/digits, збір проміжних висновків. |
| 08.10 | Розробка скрипту `scripts/summarize_suite_results.py` для об’єднання статистик. |
| 15.10 | Верифікація експериментів на breast_cancer, впровадження контролю версій конфігурацій. |
| 22.10 | Аналіз стабільності на synthetic balanced/easy/medium наборах, робота з seed-множинами. |
| 28.10 | Підготовка матеріалів для майбутніх тез, формування плану покращення візуалізацій. |
| 04.11 | Розширення `src/mle_star_ablation/stats.py`: додано `_t_to_z_score`, колонку `z_statistic`. |
| 07.11 | Імплементація `_build_pairwise_matrix` у `src/mle_star_ablation/viz.py`, проєктування heatmap-генератора. |
| 11.11 | Розробка функції `plot_statistical_overview`, вибудова композиції з box/violin/heatmap на одному полотні. |
| 14.11 | Повний перезапуск експериментального пакету без `--no-plots`; перевірка коректності нових PNG. |
| 18.11 | Актуалізація `results/aggregated_summary.csv`, перевірка довжин інтервалів довіри та `n_runs`. |
| 20.11 | Підготовка описової статистики, узагальнення впливу кожного компонента пайплайна на метрики. |
| 23.11 | Чернетка звіту, підготовка додатків з посиланнями на графіки та таблиці. |
| 24.11 | Остаточна перевірка артефактів, здача звіту керівникам практики. |

## 6. Опис виконаних робіт
### 6.1 Організаційний етап
Погоджено календарний план, сформовано перелік артефактів, з якими необхідно ознайомитися (`docs/ADK_CLI_USAGE.md`, `docs/MODEL_COMPARISON_DETAILED.md`). Проведено серію інструктажів, оформлено доступи до хмарних ресурсів та репозиторію. Розроблено власний трекер задач у `reports/` та налаштовано базові Git-налаштування для командної роботи.

### 6.2 Підготовка середовища та генерація пайплайнів
У ході практики було не лише запущено поодинокі експерименти, а й послідовно розбудовано технічну інфраструктуру, здатну програмно виконувати серії експериментів та автоматично будувати й модифікувати ML-пайплайни.
Оновлено `scripts/run_experiment_suite.py`, що дозволило запускати серії експериментів однією командою та передавати конфігурацію (`minimal`, `no_scaling`, `no_feature_engineering`, `no_tuning`, `no_ensemble`, `full`). Виконано інтеграцію з Gemini API (режими Flash, Flash Lite), налагоджено кешування відповідей і логування запитів. Підготовлено шаблони промптів для класифікаційних і регресійних сценаріїв.
Введено окремий конфігураційний файл `configs/ablation_config.yaml`, у якому формалізовано правила відключення компонентів для кожної конфігурації. Таким чином, зміна дизайну ablation-експерименту не вимагає переписування коду.

### 6.3 Проведення ablation-експериментів
Для кожного датасету проведено не менше трьох повторів з різними seed, що дозволило розрахувати середні значення, стандартні відхилення та 95%-довірчі інтервали. Експерименти охопили набори iris, wine, digits, breast_cancer, balanced synthetic, california housing, diabetes, synthetic_easy/medium. Результати для кожного запуску збережено у власних каталогах `results/<task>/<timestamp>/`. Згенеровані пайплайни задокументовано у `generated_pipelines/`.

### 6.4 Статистичне узагальнення та візуалізація
Модуль `src/mle_star_ablation/stats.py` доповнено функцією `_t_to_z_score`, що дозволило переводити $t$-статистику у $z$-шкалу за формулою $z = \frac{t}{\sqrt{\nu}}$, де $\nu$ — число ступенів вільності. Вихідні таблиці порівнянь тепер містять колонки `p_value`, `t_statistic`, `z_statistic`, `cohens_d` та `mean_diff`. У `src/mle_star_ablation/viz.py` реалізовано `_build_pairwise_matrix` для трансформації плоских таблиць у симетричні матриці, автоматизовано генерацію набору теплових карт (`pvalue_heatmap.png`, `tstat_heatmap.png`, `zscore_heatmap.png`, `mean_diff_heatmap.png`, `cohensd_heatmap.png`). Додатково створено композиційний графік `statistical_overview.png`, що об'єднує boxplot, violin plot та heatmap зі спільними легендами.

### 6.5 Документування та підсумки
Оновлено `results/aggregated_summary.csv`, перевірено узгодженість колонок `ci_lower/ci_upper` та `n_runs`. Зібрано ключові візуальні артефакти у `results/.../`. Підготовлено звіт, щоденник та пакет додатків (посилання на PNG, опис конфігурацій, інструкції для повторення експериментів). Проведено самооцінку ризиків і сформовано рекомендації щодо подальших досліджень.

## 7. Результати експериментів та аналітика
### 7.1 Зведена таблиця точностей (класифікація)
| Датасет | Найкраща конфігурація (mean accuracy) | Найбільше падіння (конфігурація → mean) | Δ точності |
| :-- | :-- | :-- | :-- |
| digits | `no_feature_engineering` → **0.984** | `no_scaling` → 0.905 | −0.079 |
| wine | `full` → **0.981** | `no_scaling` → 0.667 | −0.314 |
| breast_cancer | `minimal`/`no_feature_engineering` → **0.942** | `no_scaling` → 0.842 | −0.100 |
| iris | `no_scaling` → **0.978** | `full` → 0.922 | −0.056 |
| synthetic_balanced | `no_feature_engineering` → **0.899** | `minimal` → 0.885 | −0.014 |

**Висновки:** масштабування критичне для wine та breast_cancer (втрати понад 10 п.п.), тоді як для iris надмірне масштабування навіть шкодить через компактність ознак. Видалення feature engineering виявилось майже безболісним, що вказує на достатність LLM-генерованих базових трансформацій.

### 7.2 Зведена таблиця $R^2$ (регресія)
| Датасет | Найкраща конфігурація (mean $R^2$) | Найбільше падіння | Δ $R^2$ |
| :-- | :-- | :-- | :-- |
| california housing | `minimal` → **0.783** | `no_scaling` → −0.001 | −0.784 |
| diabetes | `full` → **0.494** | `minimal` → 0.462 | −0.032 |
| synthetic_easy | `minimal` → **0.981** | `no_scaling` → 0.954 | −0.027 |
| synthetic_medium | `no_feature_engineering` → **0.949** | `full` → 0.925 | −0.024 |

**Висновки:** для задач регресії виявлено чутливість до коректного масштабування (особливо cal_housing), тоді як глибоке налаштування (`full`) не завжди виправдане — для synth_medium воно знижує точність через переобладнання.

### 7.3 Візуалізація результатів
- Основні графіки зберігаються в `results/<task>/<timestamp>/` і включають попарні матриці статистик (z, t, p), а також композиційні оглядові фігури (boxplot + violin + heatmap).

<img src="../results/cls_wine/gemini_2.5_flash_lite_wine_pipeline_wrapper/zscore_heatmap.png" alt="Z-score heatmap (wine)" width="640" />
*Рисунок 1. Матриця z-статистик для Wine (Gemini 2.5 Flash Lite)*

<img src="../results/reg_california/gemini_live_california-housing-prices_pipeline_wrapper/statistical_overview.png" alt="Statistical overview (California housing)" width="640" />
*Рисунок 2. Оглядовий графік для California Housing (boxplot + violin + heatmap)*

<img src="../results/cls_digits/gemini_2.5_flash_lite_digits_pipeline_wrapper/tstat_heatmap.png" alt="T-stat heatmap (digits)" width="640" />
*Рисунок 3. Матриця t-статистик для Digits (Gemini 2.5 Flash Lite)*

<img src="../results/cls_breast_cancer/gemini_2.5_flash_lite_breast_cancer_pipeline_wrapper/pvalue_heatmap.png" alt="P-value heatmap (breast cancer)" width="640" />
*Рисунок 4. P-value heatmap для Breast Cancer (Gemini 2.5 Flash Lite)*

<img src="../results/cls_iris/gemini_2.5_flash_lite_iris_pipeline_wrapper/statistical_overview.png" alt="Statistical overview (iris)" width="640" />
*Рисунок 5. Оглядовий графік для Iris (boxplot + violin + heatmap)*

Усі зображення підготовлено до друку (MPL backend Agg, роздільна здатність 300 dpi).

### 7.4 Статистичні висновки (зведено)

- **cls_breast_cancer:** `no_feature_engineering` — 0.9557 ± 0.0162 (CI [0.94811, 0.96329]); ANOVA значущий, `no_scaling` суттєво гірше. Див. `results/cls_breast_cancer/gemini_2.5_flash_lite_breast_cancer_pipeline_wrapper/statistical_overview.png`.
- **cls_digits:** `no_feature_engineering` — 0.9822 ± 0.00627 (CI [0.97929, 0.98516]); ANOVA значущий, але абсолютні різниці між топ‑конфігураціями малі. Див. `results/cls_digits/gemini_2.5_flash_lite_digits_pipeline_wrapper/comparison_boxplot.png` і `tstat_heatmap.png`.
- **cls_iris:** `no_feature_engineering` — 0.9633 ± 0.02841 (CI [0.95004, 0.97663]); значущі відмінності проти `full`; перевірити фолди CV. Див. `results/cls_iris/gemini_2.5_flash_lite_iris_pipeline_wrapper/statistical_overview.png`.
- **cls_synthetic_balanced:** відмінностей немає (ANOVA p ≈ 0.9955) — контрольна перевірка пройдена; див. `results/cls_synthetic_balanced/gemini_2.5_flash_lite_digits_pipeline_wrapper/statistical_overview.png`.
- **cls_wine:** `no_tuning` — 0.9833 ± 0.01890 (CI [0.97449, 0.99218]); масштабування критично важливе. Див. `results/cls_wine/gemini_2.5_flash_lite_wine_pipeline_wrapper/zscore_heatmap.png`.
- **reg_california:** `minimal` — 0.7822 ± 0.00896 (CI [0.77799, 0.78638]); великі відмінності → перевірити ensemble/full реалізації та preprocessing. Див. `results/reg_california/gemini_live_california-housing-prices_pipeline_wrapper/statistical_overview.png`.
- **reg_diabetes:** немає значущих відмінностей (ANOVA p ≈ 0.98), великі std — рекомендовано збільшити N або змінити метрику. Див. `results/reg_diabetes/gemini_live_california-housing-prices_pipeline_wrapper/statistical_overview.png`.

Коротке резюме: n=20 забезпечило стабільні CI для класифікаційних задач; там, де виявлено великі ефекти, варто перевірити реалізації preprocessing/ensemble, а там, де ефект малий — оцінювати практичну значущість (Cohen's d) поряд зі статистичною.

## 8. Підсумкові висновки та рекомендації
1. **Цілі практики досягнуті:** реалізовано повний цикл AutoML-дослідження, розширено функціонал статистичного модуля, отримано відтворювані результати.
2. **Ключовий технічний внесок:** додано $z$-статистику та автоматизовану генерацію матриць порівнянь, створено нові heatmap-и та інтегрований оглядовий графік, що підвищує якість аналітики.
3. **Аналітичні інсайти:** підтверджено гіпотезу про схильність LLM до over-engineering. У багатьох випадках (наприклад, `digits`, `synthetic_medium`) відключення блоку Feature Engineering не погіршило, а покращило метрики, що свідчить про надлишковість згенерованих трансформацій. Водночас масштабування залишається критичним фактором.
4. **Вибір моделі Gemini:** Для практики було обрано `Gemini 2.5 Flash Lite`. Окрім балансу швидкості та вартості, вибір обґрунтовано високою валідністю генерованого коду: попередній аналіз показав відсутність синтаксичних помилок у >95% випадків, що дозволяє використовувати модель в автоматизованих контурах без ручного втручання.
5. **Обмеження дослідження:** Для попередньої оцінки ефектів (pilot study) було використано $N=3$ повтори на конфігурацію. Такий обсяг достатній для виявлення великих ефектів, але недостатній для надійної інтерпретації малих або граничних відмінностей. Для фінальної валідації та підвищення статистичної потужності рекомендовано розширити серію експериментів до $N=20$ повторів.
6. **Рекомендації:**
   - Розширити перелік конфігурацій (окремі імпутери, PCA, різні види scaler) та прогнати їх через оновлений візуальний пайплайн.
   - Автоматизувати формування підсумкових презентацій (експорт heatmap у PDF, зведення таблиць у LaTeX).
   - Валідувати результати на зовнішніх датасетах (наприклад, tabular із OpenML) для підготовки публікації.

## 9. Підписи
| Посада | ПІБ | Підпис | Дата |
| :-- | :-- | :-- | :-- |
| Студент | Фефелов І.О. | /Фефелов І.О./ | «24» листопада 2025 р. |
| Керівник від підприємства | О. В. Нестеренко | ____________________ | «24» листопада 2025 р. |
| Керівник від Академії | д.т.н., професор Кавун С.В. | ____________________ | «24» листопада 2025 р. |

## 10. Додатки
1. `results/aggregated_summary.csv` — агреговані метрики для всіх задач.
2. `results/**/statistical_overview.png` — оглядові графіки для кожного датасету.
3. `results/**/zscore_heatmap.png` та супутні теплові карти.
4. `generated_pipelines/*.py` — згенеровані Gemini-пайплайни для відтворення експериментів.
5. Детальні таблиці та вибірка графіків: `reports/detailed_stats.md` (вставлені нижче).

## Додаток A — Детальні таблиці та графіки по експериментам

<!-- BEGIN DETAILED_STATS -->



## 11. Список використаних джерел
1. Nam, J., Yoon, J., Chen, J., Shin, J., Arık, S. Ö., & Pfister, T. (2025). *MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement*. arXiv preprint arXiv:2506.15692. URL: https://arxiv.org/abs/2506.15692
2. Trirat, P., Jeong, W., & Hwang, S. J. (2025). *AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML*. In *Forty-second International Conference on Machine Learning*.
3. Tornede, T., et al. (2025). *A practical evaluation of AutoML tools for binary, multiclass, and regression problems*. *Scientific Reports*, 15, 2149.
4. Feurer, M., & Hutter, F. (2019). *Hyperparameter Optimization*. In *Automated Machine Learning*. Springer, Cham.
5. Google AI for Developers. *Gemini API Documentation*. URL: https://ai.google.dev/docs
