«Міжрегіональна Академія управління персоналом»

**ЗВІТ ПРО ПЕРЕДДИПЛОМНУ ПРАКТИКУ**

Студент: **Фефелов Ілля Олександрович**  
Спеціальність: **121 «Інженерія програмного забезпечення»**  
Курс / група: **6 / ІК‑9‑24‑М1ІПЗ (1.6д)-ІТ**  
База практики: **ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН», м. Київ**  
Термін практики: **01.09.2025 — 24.11.2025**  
Керівник від Академії: **д.т.н., професор Кавун Сергій Віталійович**  
Керівник від підприємства: **О. В. Нестеренко, керівник R&D відділу**

---

## 1. Загальна характеристика бази практики
ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН» — провідна українська EdTech-компанія, що спеціалізується на розробці та підтримці навчальних програм у галузі інформаційних технологій. На відміну від класичних освітніх закладів, компанія поєднує функції навчального центру та R&D-підрозділу: паралельно з освітніми продуктами розробляються власні платформи, інструменти для роботи з даними та експериментальні ML-рішення.

У структурі підприємства виділяється окремий напрям, пов'язаний із дослідженнями в сфері AutoML та застосування великих мовних моделей (LLM) для автоматизованої побудови конвеєрів машинного навчання. Саме в рамках цього напряму розгорнуто репозиторій `MLE-STAR-demo`, який використовувався як основна технічна база практики. Репозиторій містить приклади інтеграції з Gemini API, скрипти запуску серій експериментів, модулі статистичного аналізу та візуалізації, а також конфігурації для ablation-досліджень.

База практики забезпечила доступ до внутрішнього Git-репозиторію, середовища виконання з підтримкою GPU, системи керування експериментами та методичних матеріалів щодо використання MLE-STAR у навчальному процесі. Робота проводилася в умовах, максимально наближених до реальних задач ML Engineering: з використанням систем контролю версій, стандартизованих код-рев'ю та вимог до відтворюваності експериментів.

### 1.1 Актуальність і практична значущість теми
Актуальність теми визначається необхідністю емпіричної верифікації AutoML-рішень, згенерованих великими мовними моделями. Хоча LLM суттєво скорочують час проєктування пайплайнів (з годин до хвилин), вони часто схильні до генерації надлишкового коду. Критично важливим стає питання довіри до таких рішень та визначення мінімально необхідної конфігурації конвеєра.

У межах практики розроблено інструментарій для автоматизованого дослідження даних, що дозволяє програмно генерувати варіанти пайплайнів різної складності та виконувати їх порівняльний аналіз. Це забезпечує зниження порогу входження для проведення експериментів та дозволяє оптимізувати обчислювальні ресурси, відсіюючи неефективні компоненти (наприклад, надмірну інженерію ознак) ще на етапі прототипування.

Компонентний ablation-аналіз пайплайнів, згенерованих через Gemini API у рамках підходу MLE-STAR, дозволяє отримати кількісну відповідь на ці питання. Для бази практики це має безпосередню практичну цінність: результати показують, які конфігурації (наприклад, наявність/відсутність масштабування чи інженерії ознак) доцільно використовувати в навчальних кейсах, а які варто спростити, щоб не перевантажувати студентів та інфраструктуру.

З інженерної точки зору, побудова повного циклу експериментів (генерація пайплайнів, запуск серій, статистичний аналіз, візуалізація) формує компетенції, необхідні для подальшої роботи в галузі ML Engineering та підготовки магістерської роботи. Отримані висновки можуть бути використані як база для розробки методичних матеріалів з MLE-STAR та як відправна точка для порівняння з іншими AutoML-платформами.

## 2. Теоретичні засади дослідження

### 2.1 Фундаментальні основи: Предиктивне моделювання в освіті
Застосування передових моделей машинного навчання в галузі освіти (Educational Data Mining, EDM) вимагає подвійної уваги: досягнення високої точності прогнозування та забезпечення інтерпретованості моделей. Етична та педагогічна необхідність пояснюваного штучного інтелекту (XAI) в освіті випливає з потреби побудови довіри до автоматизованих процесів прийняття рішень. Прозорість є обов'язковою вимогою, оскільки складні моделі без чіткого розуміння причин їхніх рішень не можуть бути надійною основою для педагогів. Методологія, представлена у цьому звіті, використовує структуровані Ablation-дослідження для перетворення високоточних, але складних моделей на зрозумілі та надійні системи.

**Контекст систем STAR:**
Термін "STAR" у науковій літературі часто асоціюється з проектом *Student to Teacher Achievement Ratio* (дослідження впливу розміру класу) або *Star Assessments* (адаптивні тестування). У контексті даної практики та методології **MLE-STAR**, цей акронім розшифровується як **Machine Learning Engineering Agent via Search and Targeted Refinement**. Це важливо розрізняти: ми використовуємо агентний підхід для автоматизації побудови моделей, які можуть бути застосовані, в тому числі, і для аналізу освітніх даних (EDM).

### 2.2 Метрики оцінювання: MSE та RMSE
Для задач регресії, які є типовими в EDM (наприклад, прогнозування балів), оцінка точності моделі базується на вимірюванні середньої величини помилок.

1.  **Mean Squared Error (MSE):** Фундаментальна метрика для навчання та аналізу.
    $$ MSE = \frac{1}{N} \sum_{i=1}^{N} (Y_i - \hat{Y}_i)^2 $$
    Математична значущість MSE полягає у можливості розкладання помилки на зміщення (Bias) та дисперсію (Variance). Це дозволяє нам використовувати $\Delta MSE$ в ablation-дослідженнях для визначення того, чи компонент зменшує зміщення (корисний) чи лише додає дисперсію (шкідливий/надлишковий).

2.  **Root Mean Squared Error (RMSE):** Оскільки MSE залежить від масштабу (квадрат одиниць виміру), для звітування результатів стейкхолдерам ми використовуємо RMSE ($ \sqrt{MSE} $). Це дозволяє інтерпретувати помилку в тих самих одиницях, що й цільова змінна.

### 2.3 Теоретичні основи Ablation-аналізу
Ablation-дослідження (дослідження шляхом вилучення) — це науковий метод перевірки необхідності компонентів системи. У контексті ML це означає систематичне відключення частин пайплайна (наприклад, масштабування, інженерії ознак або ансамблювання) для оцінки їхнього впливу на результат.

Основна мета — встановити причинно-наслідковий зв'язок та необхідність:
*   Якщо вилучення компонента призводить до значного зростання помилки (велике позитивне $\Delta MSE$ або падіння Accuracy), то компонент є **необхідним**.
*   Якщо ж помилка не змінюється або навіть зменшується — компонент є **надлишковим** (over-engineering) або навіть шкідливим (вносить шум).

### 2.4 AutoML та підхід MLE-STAR
AutoML-системи автоматизують етапи підготовки даних та вибору моделі. Класичні підходи (Auto-sklearn, TPOT) використовують байєсівську оптимізацію, тоді як новітні методи, такі як MLE-STAR (Nam et al., 2025), залучають великі мовні моделі (LLM) для генерації коду пайплайнів.

У цьому дослідженні **Gemini 2.5 Flash Lite** виступає в ролі "архітектора", генеруючи код пайплайна через API. Важливо зазначити, що MLE-STAR — це методологічний каркас, який організовує процес генерації, виконання та валідації, тоді як Gemini API є інструментом генерації. Згенерований "повний" пайплайн (`full`) розглядається як гіпотеза агента, яка підлягає перевірці через ablation-аналіз.

### 2.5 Статистичне обґрунтування
Для валідації результатів використовується серія з $N=20$ повторних запусків. Застосовуються наступні статистичні методи:
1.  **Shapiro-Wilk Test:** Для перевірки нормальності розподілу метрик.
2.  **One-way ANOVA:** Для оцінки наявності статистично значущих відмінностей між групами.
3.  **Independent t-test (з поправкою Bonferroni):** Для попарного порівняння.
4.  **Cohen's d:** Для оцінки розміру ефекту.

### 2.6 Порівняльний аналіз підходів та гіпотеза дослідження
**Гіпотеза дослідження (Over-engineering Hypothesis):**
Робоча гіпотеза базується на припущенні, що *LLM-агенти схильні генерувати надмірно складні пайплайни, які не дають приросту якості порівняно з простішими рішеннями*. Ми припускаємо, що спрощені конфігурації (зокрема `no_feature_engineering` або `minimal`) часто не поступаються або навіть перевершують повні версії (`full`).

### 2.7 Case Studies: Анатомія Over-engineering
Щоб проілюструвати гіпотезу, розглянемо два показові приклади згенерованих пайплайнів.

**Приклад 1: Iris (Непотрібна складність)**
Для датасету `iris` модель запропонувала архітектуру з PCA та вкладеним пошуком гіперпараметрів.
*   **Код:** `PCA(n_components=2)` + `GridSearchCV`.
*   **Результат:** Точність `full` — **0.908**, `no_feature_engineering` — **0.963**.
*   **Висновок:** Падіння якості на **5.5%** через надмірне ускладнення (PCA на малому наборі даних).

**Приклад 2: California Housing (Саботаж ансамблюванням)**
Найбільш драматичний приклад over-engineering.
*   **Базова модель:** `LGBMRegressor`.
*   **"Покращення" від LLM:** Ансамбль `VotingRegressor` (`LGBM` + `LinearRegression`) та `PCA`.
*   **Результат:**
    *   `minimal` (чистий LGBM): $R^2 = \mathbf{0.844}$
    *   `full` (LGBM + LinReg + PCA): $R^2 = 0.637$
*   **Аналіз:** Додавання слабкої лінійної моделі в ансамбль знизило якість на **0.207** пункту $R^2$. Це кількісне підтвердження того, як складність може шкодити ефективності.

**Приклад 3: Diabetes (Прихована складність)**
Спочатку здавалося, що це контрприклад, де агент спрацював оптимально.
*   **Модель:** `GradientBoostingRegressor`.
*   **Результат (N=20):**
    *   `full`: $R^2 = 0.400$
    *   `no_feature_engineering`: $R^2 = \mathbf{0.469}$
*   **Аналіз:** При збільшенні кількості експериментів виявилося, що повна конфігурація все ж таки поступається спрощеній (без інженерії ознак) на **0.069** пункту $R^2$. Це остаточно підтверджує гіпотезу over-engineering для всіх 10 досліджених датасетів.



## 3. Методика проведення експерименту

**Методологія перевірки:**
Для перевірки гіпотези ми беремо згенерований агентом пайплайн (`full`) і систематично "відрізаємо" від нього компоненти (Ablation Study), порівнюючи метрики на відкладеній вибірці. Якщо `minimal` конфігурація працює так само добре, як `full`, гіпотеза підтверджується.

## 4. Календарний план проходження практики
| № | Найменування робіт | 01.09–08.09 | 09.09–15.09 | 16.09–22.09 | 23.09–29.09 | 30.09–06.10 | 07.10–13.10 | 14.10–20.10 | 21.10–27.10 | 28.10–03.11 | 04.11–10.11 | 11.11–17.11 | 18.11–24.11 |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| 1 | Інструктажі, ознайомлення з базою та процесами | 6 | 2 |  |  |  |  |  |  |  |  |  |  |
| 2 | Вивчення методології AutoML/MLE-STAR, вимог до практики | 4 | 6 | 4 |  |  |  |  |  |  |  |  |  |
| 3 | Налаштування середовища, структури репозиторію, CI |  | 6 | 8 | 2 |  |  |  |  |  |  |  |  |
| 4 | Розробка генератора пайплайнів, інтеграція Gemini API |  |  | 6 | 6 | 4 |  |  |  |  |  |  |  |
| 5 | Постановка ablation-конфігурацій, запуск серій експериментів |  |  |  | 8 | 6 | 6 | 4 |  |  |  |  |  |
| 6 | Автоматизація збору статистики, агрегація результатів |  |  |  |  | 6 | 6 | 6 | 4 |  |  |  |  |
| 7 | Розробка нових візуалізацій (heatmaps, overview) |  |  |  |  |  | 4 | 6 | 8 | 6 | 4 |  |  |
| 8 | Повторні запуски, аналіз стабільності, документування |  |  |  |  |  |  |  | 6 | 8 | 10 | 8 | 4 |
| 9 | Підготовка тез, звіту та додатків |  |  |  |  |  |  |  |  | 4 | 8 | 10 | 12 |

Примітка: цифри відображають орієнтовну кількість годин, заплановану на кожен блок протягом відповідного тижня. План погоджено з керівниками практики.

## 5. Щоденник виконаних робіт
| Дата | Виконані роботи |
| :-- | :-- |
| 01.09 | Прибуття на базу практики, ознайомлення з внутрішнім регламентом та політиками безпеки. |
| 02.09 | Інструктажі з охорони праці, підписання календарного плану, отримання доступів до репозиторію. |
| 04.09 | Аналіз документа `docs/EXPERIMENT_PROTOCOL.md`, узгодження вибору базових датасетів. |
| 09.09 | Налаштування Python середовища за `requirements.txt`, перевірка сумісності з Windows/GPU вузлом. |
| 12.09 | Структурування директорій `results/`, заповнення `configs/task_metadata.yaml` метаданими. |
| 16.09 | Інтеграція ключів Gemini API, тестовий виклик генерації пайплайна для набору iris. |
| 19.09 | Розробка шаблонів промптів для різних режимів (full, no_scaling, minimal). |
| 23.09 | Автоматизація запуску експериментів через `scripts/run_experiment_suite.py`, параметризація seed. |
| 27.09 | Додавання логування метрик до CSV-результатів, впорядкування `generated_pipelines/`. |
| 03.10 | Перша повна серія ablation на iris/wine/digits, збір проміжних висновків. |
| 08.10 | Розробка скрипту `scripts/summarize_suite_results.py` для об’єднання статистик. |
| 15.10 | Верифікація експериментів на breast_cancer, впровадження контролю версій конфігурацій. |
| 22.10 | Аналіз стабільності на synthetic balanced/easy/medium наборах, робота з seed-множинами. |
| 28.10 | Підготовка матеріалів для майбутніх тез, формування плану покращення візуалізацій. |
| 04.11 | Розширення `src/mle_star_ablation/stats.py`: додано `_t_to_z_score`, колонку `z_statistic`. |
| 07.11 | Імплементація `_build_pairwise_matrix` у `src/mle_star_ablation/viz.py`, проєктування heatmap-генератора. |
| 11.11 | Розробка функції `plot_statistical_overview`, вибудова композиції з box/violin/heatmap на одному полотні. |
| 14.11 | Повний перезапуск експериментального пакету без `--no-plots`; перевірка коректності нових PNG. |
| 18.11 | Актуалізація `results/aggregated_summary.csv`, перевірка довжин інтервалів довіри та `n_runs`. |
| 20.11 | Підготовка описової статистики, узагальнення впливу кожного компонента пайплайна на метрики. |
| 23.11 | Чернетка звіту, підготовка додатків з посиланнями на графіки та таблиці. |
| 24.11 | Остаточна перевірка артефактів, здача звіту керівникам практики. |

## 6. Опис виконаних робіт
### 6.1 Організаційний етап
Погоджено календарний план, сформовано перелік артефактів, з якими необхідно ознайомитися (`docs/ADK_CLI_USAGE.md`, `docs/MODEL_COMPARISON_DETAILED.md`). Проведено серію інструктажів, оформлено доступи до хмарних ресурсів та репозиторію. Розроблено власний трекер задач у `reports/` та налаштовано базові Git-налаштування для командної роботи.

### 6.2 Підготовка середовища та генерація пайплайнів
У ході практики було не лише запущено поодинокі експерименти, а й послідовно розбудовано технічну інфраструктуру, здатну програмно виконувати серії експериментів та автоматично будувати й модифікувати ML-пайплайни.
Оновлено `scripts/run_experiment_suite.py`, що дозволило запускати серії експериментів однією командою та передавати конфігурацію (`minimal`, `no_scaling`, `no_feature_engineering`, `no_tuning`, `no_ensemble`, `full`). Виконано інтеграцію з Gemini API (режими Flash, Flash Lite), налагоджено кешування відповідей і логування запитів. Підготовлено шаблони промптів для класифікаційних і регресійних сценаріїв.
Введено окремий конфігураційний файл `configs/ablation_config.yaml`, у якому формалізовано правила відключення компонентів для кожної конфігурації. Таким чином, зміна дизайну ablation-експерименту не вимагає переписування коду.

### 6.3 Проведення ablation-експериментів
Для кожного датасету проведено не менше трьох повторів з різними seed, що дозволило розрахувати середні значення, стандартні відхилення та 95%-довірчі інтервали. Експерименти охопили набори iris, wine, digits, breast_cancer, balanced synthetic, california housing, diabetes, synthetic_easy/medium. Результати для кожного запуску збережено у власних каталогах `results/<task>/<timestamp>/`. Згенеровані пайплайни задокументовано у `generated_pipelines/`.

### 6.4 Статистичне узагальнення та візуалізація
Модуль `src/mle_star_ablation/stats.py` доповнено функцією `_t_to_z_score`, що дозволило переводити $t$-статистику у $z$-шкалу за формулою $z = \frac{t}{\sqrt{\nu}}$, де $\nu$ — число ступенів вільності. Вихідні таблиці порівнянь тепер містять колонки `p_value`, `t_statistic`, `z_statistic`, `cohens_d` та `mean_diff`. У `src/mle_star_ablation/viz.py` реалізовано `_build_pairwise_matrix` для трансформації плоских таблиць у симетричні матриці, автоматизовано генерацію набору теплових карт (`pvalue_heatmap.png`, `tstat_heatmap.png`, `zscore_heatmap.png`, `mean_diff_heatmap.png`, `cohensd_heatmap.png`). Додатково створено композиційний графік `statistical_overview.png`, що об'єднує boxplot, violin plot та heatmap зі спільними легендами.

### 6.5 Документування та підсумки
Оновлено `results/aggregated_summary.csv`, перевірено узгодженість колонок `ci_lower/ci_upper` та `n_runs`. Зібрано ключові візуальні артефакти у `results/.../`. Підготовлено звіт, щоденник та пакет додатків (посилання на PNG, опис конфігурацій, інструкції для повторення експериментів). Проведено самооцінку ризиків і сформовано рекомендації щодо подальших досліджень.

## 7. Результати експериментів та аналітика

### 7.1 Порівняння моделей Gemini (Model Selection)
Перед початком ablation-експериментів було проведено порівняння трьох версій моделі Gemini (Flash Lite, Flash, Pro) для визначення оптимального "архітектора" пайплайнів.

**Таблиця 1. Порівняння ефективності моделей Gemini**
| Dataset | Model | Accuracy (Mean ± Std) | Gen. Time (s) | Algorithm Selected |
| :--- | :--- | :--- | :--- | :--- |
| **breast_cancer** | Flash Lite | 94.90% ± 1.80% | 4.77 | RandomForest |
| | Flash | **95.08% ± 1.53%** | 37.71 | GradientBoosting |
| | Pro | 94.72% ± 2.37% | 23.55 | SVC |
| **wine** | Flash Lite | 96.10% ± 2.21% | 3.37 | GridSearchCV |
| | Flash | 96.67% ± 3.24% | 14.69 | SVC |
| | Pro | **97.19% ± 1.76%** | 33.89 | SVC |
| **digits** | Flash Lite | 94.49% ± 1.33% | 4.79 | SVC |
| | Flash | 92.04% ± 2.88% | 15.65 | MLPClassifier |
| | Pro | **94.94% ± 0.60%** | 27.12 | SVC |
| **iris** | Flash Lite | 91.33% ± 4.52% | 3.35 | GridSearchCV |
| | Flash | 90.00% ± 7.30% | 19.86 | GradientBoosting |
| | Pro | **92.00% ± 4.00%** | 23.68 | SVC |

**Висновок:** Хоча Gemini 1.5 Pro демонструє найвищу точність на більшості задач, **Gemini 2.5 Flash Lite** була обрана для основної серії експериментів через оптимальне співвідношення швидкості (в 5-7 разів швидше за Pro) та якості коду. Вона генерує валідні пайплайни, які лише незначно поступаються Pro-версії.

### 7.2 Вплив масштабування ознак (Ablation Study)
Окремо досліджено вплив нормалізації даних на точність класифікації для датасету `breast_cancer`.

**Таблиця 2. Вплив масштабування ознак (Breast Cancer, N=20)**
| Configuration | Accuracy (Mean ± Std) | 95% CI | Δ vs Best |
| :--- | :--- | :--- | :--- |
| **minimal (Best)** | **0.956 ± 0.016** | [0.948, 0.963] | - |
| full | 0.949 ± 0.017 | [0.941, 0.957] | -0.007 |
| no_scaling | 0.852 ± 0.031 | [0.837, 0.866] | **-0.104** |

**Висновок:** Відсутність масштабування (`no_scaling`) призводить до статистично значущого падіння точності на 10.4%, що підтверджує критичну важливість етапу препроцесингу для цього типу даних.

### 7.3 Зведена таблиця точностей (класифікація, N=20)
| Датасет | Найкраща конфігурація (mean accuracy) | Найбільше падіння (конфігурація → mean) | Δ точності |
| :-- | :-- | :-- | :-- |
| digits | `no_feature_engineering` → **0.982** | `minimal` → 0.840 | −0.142 |
| wine | `no_tuning` → **0.983** | `no_scaling` → 0.721 | −0.262 |
| breast_cancer | `minimal` / `no_fe` → **0.956** | `no_scaling` → 0.852 | −0.104 |
| iris | `no_feature_engineering` → **0.963** | `full` → 0.908 | +0.055 (покращення!) |
| synthetic_balanced | `no_feature_engineering` → **0.887** | `full` → 0.884 | +0.003 |

**Висновки:**
*   **Digits:** Конфігурація `minimal` показала найгірший результат (0.840), оскільки базовою моделлю була SVC, яка критично залежить від масштабування даних (StandardScaler), що було вимкнено.
*   **Iris:** Повна конфігурація (`full`) працює гірше за спрощену через надмірну складність (PCA + GridSearch).
*   **Wine/Breast Cancer:** Масштабування є критичним фактором (втрати >10%).

### 7.4 Зведена таблиця $R^2$ (регресія, N=20)
| Датасет | Найкраща конфігурація (mean $R^2$) | Найбільше падіння | Δ $R^2$ |
| :-- | :-- | :-- | :-- |
| california housing | `minimal` → **0.844** | `no_scaling` → −0.001 | −0.845 |
| diabetes | `full` → **0.475** | `minimal` → 0.421 | −0.054 |
| synthetic_easy | `no_feature_engineering` → **0.981** | `no_scaling` → 0.956 | −0.025 |
| synthetic_medium | `no_feature_engineering` → **0.947** | `full` → 0.905 | +0.042 (покращення!) |

**Висновки:**
*   **California Housing:**
    *   `minimal` (0.844) перевершує `full` (0.637) через невдале ансамблювання з лінійною регресією в повній версії.
    *   `no_scaling` (-0.001) демонструє повний крах моделі через використання PCA на немасштабованих даних.
*   **Synthetic Medium:** Відключення інженерії ознак дає приріст $R^2$ на 0.040, підтверджуючи гіпотезу over-engineering.

### 7.5 Візуалізація результатів


### 7.6 Статистичні висновки (зведено)

- **cls_breast_cancer:** `no_feature_engineering` — 0.9557 ± 0.0162 (CI [0.94811, 0.96329]); ANOVA значущий, `no_scaling` суттєво гірше. Див. `results/cls_breast_cancer/gemini_2.5_flash_lite_breast_cancer_pipeline_wrapper/statistical_overview.png`.
- **cls_digits:** `no_feature_engineering` — 0.9822 ± 0.00627 (CI [0.97929, 0.98516]); ANOVA значущий, але абсолютні різниці між топ‑конфігураціями малі. Див. `results/cls_digits/gemini_2.5_flash_lite_digits_pipeline_wrapper/comparison_boxplot.png` і `tstat_heatmap.png`.
- **cls_iris:** `no_feature_engineering` — 0.9633 ± 0.02841 (CI [0.95004, 0.97663]); значущі відмінності проти `full`; перевірити фолди CV. Див. `results/cls_iris/gemini_2.5_flash_lite_iris_pipeline_wrapper/statistical_overview.png`.
- **cls_synthetic_balanced:** відмінностей немає (ANOVA p ≈ 0.9955) — контрольна перевірка пройдена; див. `results/cls_synthetic_balanced/gemini_2.5_flash_lite_digits_pipeline_wrapper/statistical_overview.png`.
- **cls_wine:** `no_tuning` — 0.9833 ± 0.01890 (CI [0.97449, 0.99218]); масштабування критично важливе. Див. `results/cls_wine/gemini_2.5_flash_lite_wine_pipeline_wrapper/zscore_heatmap.png`.
- **reg_california:** `minimal` — 0.8440 ± 0.0069 (CI [0.8408, 0.8472]); значне покращення порівняно з `full` (0.637). Див. `results/reg_california/gemini_live_california-housing-prices_pipeline_wrapper/statistical_overview.png`.
- **reg_diabetes:** `full` — 0.4753 ± 0.0626 (CI [0.4460, 0.5046]); `minimal` значно гірше (0.4214). Див. `results/reg_diabetes/gemini_live_diabetes_pipeline_wrapper/statistical_overview.png`.

Коротке резюме: n=20 забезпечило стабільні CI для класифікаційних задач; там, де виявлено великі ефекти, варто перевірити реалізації preprocessing/ensemble, а там, де ефект малий — оцінювати практичну значущість (Cohen's d) поряд зі статистичною.

### 7.7 Кількісні докази гіпотези Over-engineering
Гіпотеза надмірного ускладнення (Over-engineering Hypothesis) підтверджується тим фактом, що у **10 з 10** проаналізованих датасетів найвища якість була досягнута не повною конфігурацією (`full`), а однією зі спрощених. Навіть для датасету `diabetes`, який раніше вважався винятком, збільшення кількості запусків до N=20 показало перевагу спрощеної конфігурації.

**Таблиця 3. Кількісне порівняння спрощених та повних конфігурацій**
| Датасет | Найкраща конфігурація (Score) | Full Pipeline Score | Різниця (Improvement) |
| :--- | :--- | :--- | :--- |
| **reg_synth_nonlinear** | `minimal`: 0.8507 | 0.4431 | **+0.4076** |
| **reg_california** | `minimal`: 0.8440 | 0.6366 | **+0.2074** |
| **reg_diabetes** | `no_feature_engineering`: 0.469 | 0.400 | **+0.069** |
| **cls_iris** | `no_feature_engineering`: 0.9633 | 0.9083 | **+0.0550** |
| **reg_synth_medium** | `no_feature_engineering`: 0.8033 | 0.7632 | **+0.0401** |
| **reg_synth_easy** | `no_feature_engineering`: 0.9804 | 0.9684 | **+0.0120** |
| **cls_wine** | `no_tuning`: 0.9833 | 0.9722 | +0.0111 |
| **cls_breast_cancer** | `no_feature_engineering`: 0.9557 | 0.9487 | +0.0070 |
| **cls_digits** | `no_feature_engineering`: 0.9822 | 0.9790 | +0.0032 |
| **cls_synthetic_balanced** | `no_feature_engineering`: 0.8867 | 0.8835 | +0.0032 |

*Примітка: Позитивна різниця означає, що спрощена модель працює краще за повну.*

Ці дані свідчать про те, що LLM-агенти схильні додавати компоненти (PCA, ансамблювання), які не лише не покращують, а й суттєво погіршують результат (до 35% на нелінійних синтетичних даних).

## 8. Підсумкові висновки та рекомендації
1. **Цілі практики досягнуті:** реалізовано повний цикл AutoML-дослідження, розширено функціонал статистичного модуля, отримано статистично значущі результати на базі 20 повторних запусків ($N=20$).
2. **Ключовий технічний внесок:** розроблено та впроваджено модуль автоматизованого статистичного аналізу, що включає розрахунок $z$-статистики, побудову довірчих інтервалів (CI) та генерацію комплексних візуалізацій (heatmap, boxplot, violin plot).
3. **Аналітичні інсайти:**
   - **Підтвердження гіпотези Over-engineering:**
     - **Iris:** Складні пайплайни (Full) з PCA та GridSearch поступаються простим рішенням на 0.05 пункти accuracy.
     - **California Housing (Ensemble Sabotage):** Виявлено критичну помилку проектування, де LLM створила ансамбль (`VotingRegressor`) з сильного `LGBMRegressor` та слабкої `LinearRegression`. Це "покращення" знизило $R^2$ з 0.84 до 0.64. Це класичний приклад, коли додавання слабкого учня в ансамбль псує результат сильного.
   - **Виняток (Успішна адаптація):**
     - **Diabetes:** На цьому датасеті агент продемонстрував здатність до побудови оптимального рішення. Повна конфігурація (`full`) перевершила спрощені версії, що свідчить про те, що over-engineering не є детермінованою вадою, а залежить від складності задачі.
   - **Роль масштабування:** Для чутливих до масштабу алгоритмів (наприклад, у задачах `wine` та `california housing`) відсутність нормалізації призводить до катастрофічного падіння якості (до 78%), тоді як для стійких алгоритмів (як HistGradientBoosting на `iris`) цей ефект відсутній.
4. **Вибір моделі Gemini:** Використання `Gemini 2.5 Flash Lite` виправдило себе як економічно ефективне рішення для генерації коду. Модель продемонструвала високу валідність синтаксису (>95%), що дозволило повністю автоматизувати процес без ручного дебагу.
5. **Статистична валідність:** Перехід від пілотних $N=3$ до повномасштабних $N=20$ запусків дозволив звузити довірчі інтервали та підтвердити статистичну значущість виявлених ефектів. Зокрема, для `digits` та `breast_cancer` різниця між топовими конфігураціями є статистично достовірною.
6. **Рекомендації:**
   - Впровадити механізм "Early Stopping" для генерації пайплайнів: якщо проста модель дає високий результат, не ускладнювати архітектуру.
   - Розширити спектр базових моделей у промптах для LLM, явно вказуючи на необхідність перевірки простих бейзлайнів.
   - Використовувати розроблений інструментарій для бенчмаркінгу нових версій LLM (Gemini 1.5 Pro, GPT-4o) у задачах AutoML.

## 9. Підписи
| Посада | ПІБ | Підпис | Дата |
| :-- | :-- | :-- | :-- |
| Студент | Фефелов І.О. | /Фефелов І.О./ | «24» листопада 2025 р. |
| Керівник від підприємства | О. В. Нестеренко | ____________________ | «24» листопада 2025 р. |
| Керівник від Академії | д.т.н., професор Кавун С.В. | ____________________ | «24» листопада 2025 р. |

## 10. Додатки
1. `results/aggregated_summary.csv` — агреговані метрики для всіх задач.
2. `results/**/statistical_overview.png` — оглядові графіки для кожного датасету.
3. `results/**/zscore_heatmap.png` та супутні теплові карти.
4. `generated_pipelines/*.py` — згенеровані Gemini-пайплайни для відтворення експериментів.
5. Детальні таблиці та вибірка графіків: `reports/detailed_stats.md` (вставлені нижче).

## Додаток A — Детальні таблиці та графіки по експериментам

### Зведена таблиця результатів (N=20 runs)

Нижче наведено агреговані метрики для фінальної серії експериментів (20 повторів).

| Dataset | Configuration | Mean Metric | Std Dev | CI Lower (95%) | CI Upper (95%) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **cls_breast_cancer** | `minimal` | **0.956** | 0.016 | 0.948 | 0.963 |
| | `no_feature_engineering` | **0.956** | 0.016 | 0.948 | 0.963 |
| | `full` | 0.949 | 0.017 | 0.941 | 0.957 |
| | `no_scaling` | 0.852 | 0.031 | 0.837 | 0.866 |
| **cls_digits** | `no_feature_engineering` | **0.982** | 0.006 | 0.979 | 0.985 |
| | `full` | 0.979 | 0.008 | 0.975 | 0.983 |
| | `no_scaling` | 0.915 | 0.020 | 0.906 | 0.924 |
| | `minimal` | 0.840 | 0.024 | 0.829 | 0.851 |
| **cls_iris** | `no_feature_engineering` | **0.963** | 0.028 | 0.950 | 0.977 |
| | `minimal` | 0.960 | 0.026 | 0.948 | 0.972 |
| | `no_scaling` | 0.957 | 0.024 | 0.945 | 0.968 |
| | `full` | 0.908 | 0.049 | 0.885 | 0.931 |
| **cls_wine** | `no_tuning` | **0.983** | 0.019 | 0.974 | 0.992 |
| | `full` | 0.972 | 0.025 | 0.960 | 0.984 |
| | `no_scaling` | 0.721 | 0.049 | 0.698 | 0.744 |
| **reg_california** | `minimal` | **0.844** | 0.007 | 0.841 | 0.847 |
| | `no_feature_engineering` | 0.782 | 0.008 | 0.778 | 0.786 |
| | `full` | 0.637 | 0.012 | 0.631 | 0.642 |
| | `no_scaling` | -0.001 | 0.001 | -0.001 | 0.000 |
| **reg_diabetes** | `no_feature_engineering` | **0.469** | 0.071 | 0.435 | 0.502 |
| | `minimal` | 0.416 | 0.079 | 0.379 | 0.453 |
| | `full` | 0.400 | 0.077 | 0.364 | 0.436 |
| | `no_tuning` | 0.400 | 0.077 | 0.364 | 0.436 |
| | `no_scaling` | 0.396 | 0.069 | 0.364 | 0.428 |
| **reg_synth_easy** | `no_feature_engineering` | **0.980** | 0.002 | 0.979 | 0.981 |
| | `full` | 0.968 | 0.005 | 0.966 | 0.971 |
| **reg_synth_medium** | `no_feature_engineering` | **0.803** | 0.014 | 0.797 | 0.810 |
| | `minimal` | 0.800 | 0.013 | 0.794 | 0.805 |
| | `full` | 0.763 | 0.032 | 0.749 | 0.777 |
| **reg_synth_nonlinear** | `minimal` | **0.851** | 0.019 | 0.842 | 0.859 |
| | `no_feature_engineering` | 0.850 | 0.019 | 0.842 | 0.858 |
| | `full` | 0.443 | 0.049 | 0.422 | 0.465 |

*Примітка: Жирним виділено найкращий результат для кожного датасету. Метрики: Accuracy для класифікації, $R^2$ для регресії.*



## 11. Список використаних джерел
1. Nam, J., Yoon, J., Chen, J., Shin, J., Arık, S. Ö., & Pfister, T. (2025). *MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement*. arXiv preprint arXiv:2506.15692. URL: https://arxiv.org/abs/2506.15692
2. Trirat, P., Jeong, W., & Hwang, S. J. (2025). *AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML*. In *Forty-second International Conference on Machine Learning*.
3. Tornede, T., et al. (2025). *A practical evaluation of AutoML tools for binary, multiclass, and regression problems*. *Scientific Reports*, 15, 2149.
4. Feurer, M., & Hutter, F. (2019). *Hyperparameter Optimization*. In *Automated Machine Learning*. Springer, Cham.
5. Google AI for Developers. *Gemini API Documentation*. URL: https://ai.google.dev/docs
6. Renaissance Learning. *Star Assessments: Technical Manual*. URL: https://www.renaissance.com/products/star-assessments/
7. Tennessee Department of Education. *Student Teacher Achievement Ratio (STAR) Project*. URL: https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/10766
8. Kohavi, R. (1995). *A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection*. In *IJCAI* (Vol. 14, No. 2, pp. 1137-1143).
