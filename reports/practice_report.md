«Міжрегіональна Академія управління персоналом»

**ЗВІТ ПРО ПЕРЕДДИПЛОМНУ ПРАКТИКУ**

Студент: **Фефелов Ілля Олександрович**  
Спеціальність: **121 «Інженерія програмного забезпечення»**  
Курс / група: **6 / ІК‑9‑24‑М1ІПЗ (1.6д)-ІТ**  
База практики: **ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН», м. Київ**  
Термін практики: **01.09.2025 — 24.11.2025**  
Керівник від Академії: **д.т.н., професор Кавун Сергій Віталійович**  
Керівник від підприємства: **О. В. Нестеренко, керівник R&D відділу**

---

## 1. Загальна характеристика бази практики
ТОВ «ГОУ АЙТІ ЕДЬЮКЕЙШЕН» — провідна українська EdTech-компанія, що спеціалізується на розробці та підтримці навчальних програм у галузі інформаційних технологій. На відміну від класичних освітніх закладів, компанія поєднує функції навчального центру та R&D-підрозділу: паралельно з освітніми продуктами розробляються власні платформи, інструменти для роботи з даними та експериментальні ML-рішення.

У структурі підприємства виділяється окремий напрям, пов'язаний із дослідженнями в сфері AutoML та застосування великих мовних моделей (LLM) для автоматизованої побудови конвеєрів машинного навчання. Саме в рамках цього напряму розгорнуто репозиторій `MLE-STAR-demo`, який використовувався як основна технічна база практики. Репозиторій містить приклади інтеграції з Gemini API, скрипти запуску серій експериментів, модулі статистичного аналізу та візуалізації, а також конфігурації для ablation-досліджень.

База практики забезпечила доступ до внутрішнього Git-репозиторію, середовища виконання з підтримкою GPU, системи керування експериментами та методичних матеріалів щодо використання MLE-STAR у навчальному процесі. Робота проводилася в умовах, максимально наближених до реальних задач ML Engineering: з використанням систем контролю версій, стандартизованих код-рев'ю та вимог до відтворюваності експериментів.

### 1.1 Актуальність і практична значущість теми
Актуальність теми практики визначається швидким ростом інтересу до AutoML-рішень та інтеграції великих мовних моделей у життєвий цикл машинного навчання. LLM здатні суттєво скоротити час проєктування пайплайнів, але одночасно породжують питання довіри до автоматично згенерованих рішень: які компоненти конвеєра є дійсно необхідними, а які додають зайву складність без виграшу в якості.

Компонентний ablation-аналіз пайплайнів, згенерованих через Gemini API у рамках підходу MLE-STAR, дозволяє отримати кількісну відповідь на ці питання. Для бази практики це має безпосередню практичну цінність: результати показують, які конфігурації (наприклад, наявність/відсутність масштабування чи інженерії ознак) доцільно використовувати в навчальних кейсах, а які варто спростити, щоб не перевантажувати студентів та інфраструктуру.

З інженерної точки зору, побудова повного циклу експериментів (генерація пайплайнів, запуск серій, статистичний аналіз, візуалізація) формує компетенції, необхідні для подальшої роботи в галузі ML Engineering та підготовки магістерської роботи. Отримані висновки можуть бути використані як база для розробки методичних матеріалів з MLE-STAR та як відправна точка для порівняння з іншими AutoML-платформами.

## 2. Мета та завдання практики
**Мета:** відпрацювати повний цикл дослідження AutoML-підходу MLE-STAR із застосуванням Gemini API: від аналізу предметної області та налаштування середовища до запуску серій ablation-експериментів, статистичної інтерпретації результатів і оформлення технічної документації.

**Основні завдання:**
1. Ознайомитися зі структурою репозиторію та інфраструктурою запуску експериментів.
2. Налаштувати оточення, підключити Gemini API та автоматизувати генерацію ML-пайплайнів.
3. Провести серії ablation-експериментів на базових датасетах (iris, wine, digits, breast_cancer, california housing, diabetes, synthetic).
4. Розширити модуль статистики (`src/mle_star_ablation/stats.py`) і візуалізацій (`src/mle_star_ablation/viz.py`) для побудови теплових карт $p/t/z$-значень.
5. Перегенерувати повний набір графіків, сформувати агреговану таблицю (`results/aggregated_summary.csv`) та узагальнюючі PNG.
6. Підготувати підсумковий звіт і рекомендації щодо подальшого розвитку дослідження.

abla_{c_i} m$ значно відрізняється від нуля (де $m$ — метрика якості, $c_i$ — компонент), то компонент критичний і має залишатися в конвеєрі. Середнє падіння метрики оцінюється як $\Delta m = m_{full} - m_{cfg}$ для кожної конфігурації `cfg`.
## 3. Теоретичні засади дослідження
### 3.1 AutoML, LLM та підхід MLE-STAR
AutoML-системи спрямовані на автоматизацію етапів підготовки даних, вибору моделі та налаштування гіперпараметрів. Класичні підходи (Auto-sklearn, TPOT тощо) будують конвеєри на основі пошуку в просторі моделей і трансформацій за допомогою евристик або байєсівської оптимізації. З появою великих мовних моделей (LLM) з'явилася можливість делегувати частину інженерної роботи самим моделям: описуючи задачу природною мовою, інженер отримує готовий код пайплайна, який потім можна перевірити, модифікувати та піддати ablation-аналізу.

MLE-STAR позиціонується як інженерний шаблон, що поєднує LLM-генерацію з класичними принципами MLOps та експериментального дизайну. У цьому підході великомовна модель (у нашому випадку Gemini 2.5 Flash Lite) виконує роль «архітектора» конвеєра: на основі промпта вона пропонує послідовність кроків (імпутація пропусків, масштабування ознак, інженерія ознак, вибір базової моделі та її гіперпараметрів). Далі цей код інтегрується у стандартне Python-середовище, де його можна повторно запускати, фіксувати випадкові стани (random seed) і оцінювати якість на репрезентативних датасетах.

У межах практики було сфокусовано увагу на фіксованій моделі Gemini 2.5 Flash Lite, обраній на попередньому етапі порівняння варіантів (Flash, Flash Lite, Pro). Такий вибір дає змогу ізолювати вплив саме компонентів пайплайна, не змішуючи його з різницею між LLM-моделями. Саме ця ідея відповідає компонентному характеру MLE-STAR: генерація відбувається один раз, а далі інженер працює з набором варіантів конвеєра, керуючи їхньою складністю.

### 3.2 Компонентний ablation-аналіз конвеєрів
Компонентний ablation-аналіз (component-wise ablation) — це методологія, за якої з базового конвеєра послідовно вилучаються окремі компоненти, а зміна цільової метрики використовується як оцінка їхнього внеску. У випадку AutoML-пайплайнів, згенерованих Gemini, такими компонентами є:

- блоки препроцесингу (імпутація пропусків, масштабування ознак);
- блоки інженерії ознак (PCA, поліноміальні ознаки, генерація взаємодій);
- модулі оптимізації гіперпараметрів (тюнінг);
- ансамблювання моделей (стекінг, бустинг поверх базової моделі).

У репозиторії `MLE-STAR-demo` ці варіанти формалізовано як конфігурації `full`, `no_scaling`, `no_feature_engineering`, `no_tuning`, `no_ensemble`, `minimal`. Базовим вважається повний конвеєр `full`, а різниця між метриками $m_{full}$ та $m_{cfg}$ для конфігурації `cfg` інтерпретується як оцінка впливу компонента, що був вимкнений. У спрощеному вигляді внесок оцінюється як

$$\Delta m = m_{full} - m_{cfg},$$

де $m$ — середнє значення обраної метрики якості (accuracy, $R^2$ тощо). Якщо $\Delta m$ велике й стабільне на різних датасетах, то компонент є критичним; якщо ж різниця мала або негативна (вимкнення покращує результат), то компонент можна вважати опційним або навіть шкідливим для даного класу задач.

Узагальнюючи, MLE-STAR трактує LLM-згенерований конвеєр не як «чорну скриньку», а як набір модульних рішень, кожне з яких може бути включене або виключене. Компонентний ablation дозволяє перетворити інтуїтивні міркування про корисність scaling чи feature engineering на кількісні, статистично обґрунтовані висновки.

### 3.3 Статистичне обґрунтування порівнянь
Щоб відрізнити випадкові коливання метрик від справжнього ефекту компонента, використовується формальний статистичний апарат. Для кожного датасету та конфігурації запускається кілька повторів із різними випадковими станами (seed), на основі яких розраховується середнє значення метрики, стандартне відхилення та 95%-довірчий інтервал. Далі застосовуються:

- дисперсійний аналіз (ANOVA) — для перевірки гіпотези про відсутність різниці між кількома конфігураціями;
- парні t-тести для попарного порівняння `full` з іншими конфігураціями;
- коефіцієнт ефекту Cohen's $d$ для оцінки практичної значущості різниць.

Через відносно невелику кількість повторів t-статистика додатково переводиться в $z$-шкалу за формулою

$$z = \frac{t}{\sqrt{\nu}},$$

де $\nu$ — кількість ступенів вільності. Така нормалізація спрощує побудову теплових карт, де по осі X/Y відкладаються конфігурації, а в клітинках відображається $z$-значення або $p$-value. Це дозволяє наочно виділити пари конфігурацій, між якими різниця статистично значуща ($p < 0{,}05$), та швидко знаходити «нечутливі» компоненти, для яких різниця не виходить за межі статистичного шуму.

### 3.4 Теоретичні висновки
1. Препроцесинг (імпутація + масштабування) є єдиним блоком, що демонструє стабільно великий ефект ($|d| > 0.8$) для частини датасетів, зокрема wine та california housing. Це узгоджується з класичною теорією, згідно з якою коректне масштабування ознак критично важливе для моделей, чутливих до масштабу (kNN, SVM, лінійні моделі).
2. Інженерія ознак (PCA, поліноміальні перетворення) має контекстно залежний ефект: для низьковимірних та добре структурованих наборів (iris) вона часто призводить до перенавчання й погіршення якості. Для високовимірних задач її доцільність повинна перевірятися емпірично через ablation-аналіз, а не прийматися як аксіома.
3. Адаптація t-статистики до $z$-шкали та використання матриць попарних порівнянь дає можливість проводити мета-аналіз між різними датасетами, застосовуючи однакові порогові значення та візуальні шаблони (heatmap-и). Це робить результати більш інтерпретованими для інженерів та наукових керівників і підсилює довіру до висновків, сформульованих на основі експериментів.

## 4. Календарний план проходження практики
| № | Найменування робіт | 01.09–08.09 | 09.09–15.09 | 16.09–22.09 | 23.09–29.09 | 30.09–06.10 | 07.10–13.10 | 14.10–20.10 | 21.10–27.10 | 28.10–03.11 | 04.11–10.11 | 11.11–17.11 | 18.11–24.11 |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| 1 | Інструктажі, ознайомлення з базою та процесами | 6 | 2 |  |  |  |  |  |  |  |  |  |  |
| 2 | Вивчення методології AutoML/MLE-STAR, вимог до практики | 4 | 6 | 4 |  |  |  |  |  |  |  |  |  |
| 3 | Налаштування середовища, структури репозиторію, CI |  | 6 | 8 | 2 |  |  |  |  |  |  |  |  |
| 4 | Розробка генератора пайплайнів, інтеграція Gemini API |  |  | 6 | 6 | 4 |  |  |  |  |  |  |  |
| 5 | Постановка ablation-конфігурацій, запуск серій експериментів |  |  |  | 8 | 6 | 6 | 4 |  |  |  |  |  |
| 6 | Автоматизація збору статистики, агрегація результатів |  |  |  |  | 6 | 6 | 6 | 4 |  |  |  |  |
| 7 | Розробка нових візуалізацій (heatmaps, overview) |  |  |  |  |  | 4 | 6 | 8 | 6 | 4 |  |  |
| 8 | Повторні запуски, аналіз стабільності, документування |  |  |  |  |  |  |  | 6 | 8 | 10 | 8 | 4 |
| 9 | Підготовка тез, звіту та додатків |  |  |  |  |  |  |  |  | 4 | 8 | 10 | 12 |

Примітка: цифри відображають орієнтовну кількість годин, заплановану на кожен блок протягом відповідного тижня. План погоджено з керівниками практики.

## 5. Щоденник виконаних робіт
| Дата | Виконані роботи |
| :-- | :-- |
| 01.09 | Прибуття на базу практики, ознайомлення з внутрішнім регламентом та політиками безпеки. |
| 02.09 | Інструктажі з охорони праці, підписання календарного плану, отримання доступів до репозиторію. |
| 04.09 | Аналіз документа `docs/EXPERIMENT_PROTOCOL.md`, узгодження вибору базових датасетів. |
| 09.09 | Налаштування Python середовища за `requirements.txt`, перевірка сумісності з Windows/GPU вузлом. |
| 12.09 | Структурування директорій `results/`, заповнення `configs/task_metadata.yaml` метаданими. |
| 16.09 | Інтеграція ключів Gemini API, тестовий виклик генерації пайплайна для набору iris. |
| 19.09 | Розробка шаблонів промптів для різних режимів (full, no_scaling, minimal). |
| 23.09 | Автоматизація запуску експериментів через `scripts/run_experiment_suite.py`, параметризація seed. |
| 27.09 | Додавання логування метрик до CSV-результатів, впорядкування `generated_pipelines/`. |
| 03.10 | Перша повна серія ablation на iris/wine/digits, збір проміжних висновків. |
| 08.10 | Розробка скрипту `scripts/summarize_suite_results.py` для об’єднання статистик. |
| 15.10 | Верифікація експериментів на breast_cancer, впровадження контролю версій конфігурацій. |
| 22.10 | Аналіз стабільності на synthetic balanced/easy/medium наборах, робота з seed-множинами. |
| 28.10 | Підготовка матеріалів для майбутніх тез, формування плану покращення візуалізацій. |
| 04.11 | Розширення `src/mle_star_ablation/stats.py`: додано `_t_to_z_score`, колонку `z_statistic`. |
| 07.11 | Імплементація `_build_pairwise_matrix` у `src/mle_star_ablation/viz.py`, проєктування heatmap-генератора. |
| 11.11 | Розробка функції `plot_statistical_overview`, вибудова композиції з box/violin/heatmap на одному полотні. |
| 14.11 | Повний перезапуск експериментального пакету без `--no-plots`; перевірка коректності нових PNG. |
| 18.11 | Актуалізація `results/aggregated_summary.csv`, перевірка довжин інтервалів довіри та `n_runs`. |
| 20.11 | Підготовка описової статистики, узагальнення впливу кожного компонента пайплайна на метрики. |
| 23.11 | Чернетка звіту, підготовка додатків з посиланнями на графіки та таблиці. |
| 24.11 | Остаточна перевірка артефактів, здача звіту керівникам практики. |

## 6. Опис виконаних робіт
### 5.1 Організаційний етап
Погоджено календарний план, сформовано перелік артефактів, з якими необхідно ознайомитися (`docs/ADK_CLI_USAGE.md`, `docs/MODEL_COMPARISON_DETAILED.md`). Проведено серію інструктажів, оформлено доступи до хмарних ресурсів та репозиторію. Розроблено власний трекер задач у `reports/` та налаштовано базові Git-налаштування для командної роботи.

### 5.2 Підготовка середовища та генерація пайплайнів
Оновлено `scripts/run_experiment_suite.py`, що дозволило запускати серії експериментів однією командою та передавати конфігурацію (`minimal`, `no_scaling`, `no_feature_engineering`, `no_tuning`, `no_ensemble`, `full`). Виконано інтеграцію з Gemini API (режими Flash, Flash Lite), налагоджено кешування відповідей і логування запитів. Підготовлено шаблони промптів для класифікаційних і регресійних сценаріїв.

### 5.3 Проведення ablation-експериментів
Для кожного датасету проведено не менше трьох повторів з різними seed, що дозволило розрахувати середні значення, стандартні відхилення та 95%-довірчі інтервали. Експерименти охопили набори iris, wine, digits, breast_cancer, balanced synthetic, california housing, diabetes, synthetic_easy/medium. Результати для кожного запуску збережено у власних каталогах `results/<task>/<timestamp>/`. Згенеровані пайплайни задокументовано у `generated_pipelines/`.

### 5.4 Статистичне узагальнення та візуалізація
Модуль `src/mle_star_ablation/stats.py` доповнено функцією `_t_to_z_score`, що дозволило переводити $t$-статистику у $z$-шкалу за формулою $z = \frac{t}{\sqrt{\nu}}$, де $\nu$ — число ступенів вільності. Вихідні таблиці порівнянь тепер містять колонки `p_value`, `t_statistic`, `z_statistic`, `cohens_d` та `mean_diff`. У `src/mle_star_ablation/viz.py` реалізовано `_build_pairwise_matrix` для трансформації плоских таблиць у симетричні матриці, автоматизовано генерацію набору теплових карт (`pvalue_heatmap.png`, `tstat_heatmap.png`, `zscore_heatmap.png`, `mean_diff_heatmap.png`, `cohensd_heatmap.png`). Додатково створено композиційний графік `statistical_overview.png`, що об'єднує boxplot, violin plot та heatmap зі спільними легендами.

### 5.5 Документування та підсумки
Оновлено `results/aggregated_summary.csv`, перевірено узгодженість колонок `ci_lower/ci_upper` та `n_runs`. Зібрано ключові візуальні артефакти у `results/.../`. Підготовлено звіт, щоденник та пакет додатків (посилання на PNG, опис конфігурацій, інструкції для повторення експериментів). Проведено самооцінку ризиків і сформовано рекомендації щодо подальших досліджень.

## 7. Результати експериментів та аналітика
### 6.1 Зведена таблиця точностей (класифікація)
| Датасет | Найкраща конфігурація (mean accuracy) | Найбільше падіння (конфігурація → mean) | Δ точності |
| :-- | :-- | :-- | :-- |
| digits | `no_feature_engineering` → **0.984** | `no_scaling` → 0.905 | −0.079 |
| wine | `full` → **0.981** | `no_scaling` → 0.667 | −0.314 |
| breast_cancer | `minimal`/`no_feature_engineering` → **0.942** | `no_scaling` → 0.842 | −0.100 |
| iris | `no_scaling` → **0.978** | `full` → 0.922 | −0.056 |
| synthetic_balanced | `no_feature_engineering` → **0.899** | `minimal` → 0.885 | −0.014 |

**Висновки:** масштабування критичне для wine та breast_cancer (втрати понад 10 п.п.), тоді як для iris надмірне масштабування навіть шкодить через компактність ознак. Видалення feature engineering виявилось майже безболісним, що вказує на достатність LLM-генерованих базових трансформацій.

### 6.2 Зведена таблиця $R^2$ (регресія)
| Датасет | Найкраща конфігурація (mean $R^2$) | Найбільше падіння | Δ $R^2$ |
| :-- | :-- | :-- | :-- |
| california housing | `minimal` → **0.783** | `no_scaling` → −0.001 | −0.784 |
| diabetes | `full` → **0.494** | `minimal` → 0.462 | −0.032 |
| synthetic_easy | `minimal` → **0.981** | `no_scaling` → 0.954 | −0.027 |
| synthetic_medium | `no_feature_engineering` → **0.949** | `full` → 0.925 | −0.024 |

**Висновки:** для задач регресії виявлено чутливість до коректного масштабування (особливо cal_housing), тоді як глибоке налаштування (`full`) не завжди виправдане — для synth_medium воно знижує точність через переобладнання.

### 6.3 Візуальні артефакти
- `results/cls_digits/.../tstat_heatmap.png` — дозволяє миттєво оцінити, які конфігурації статистично відрізняються для конкретного датасету.
- `results/.../statistical_overview.png` — комбінований графік з boxplot/violin/heatmap, що дає контекст і розкид метрик у межах однієї фігури.
- `results/.../pvalue_heatmap.png` — підтримує швидке фільтрування незначущих пар (p-value > 0.05).

Усі зображення збережено у відповідних підкаталогах `results/<task>/<timestamp>/` та підготовлено до друку (MPL backend Agg, роздільна здатність 300 dpi).

## 8. Підсумкові висновки та рекомендації
1. **Цілі практики досягнуті:** реалізовано повний цикл AutoML-дослідження, розширено функціонал статистичного модуля, отримано відтворювані результати.
2. **Ключовий технічний внесок:** додано $z$-статистику та автоматизовану генерацію матриць порівнянь, створено нові heatmap-и та інтегрований оглядовий графік, що підвищує якість аналітики.
3. **Аналітичні інсайти:** масштабування є визначальним фактором для складних датасетів (wine, cal_housing), тоді як оптимізація feature engineering може бути спрощена без втрати якості.
4. **Рекомендації:**
   - Розширити перелік конфігурацій (окремі імпутери, PCA, різні види scaler) та прогнати їх через оновлений візуальний пайплайн.
   - Автоматизувати формування підсумкових презентацій (експорт heatmap у PDF, зведення таблиць у LaTeX).
   - Валідувати результати на зовнішніх датасетах (наприклад, tabular із OpenML) для підготовки публікації.

## 9. Підписи
| Посада | ПІБ | Підпис | Дата |
| :-- | :-- | :-- | :-- |
| Студент | Фефелов І.О. | /Фефелов І.О./ | «24» листопада 2025 р. |
| Керівник від підприємства | О. В. Нестеренко | ____________________ | «24» листопада 2025 р. |
| Керівник від Академії | д.т.н., професор Кавун С.В. | ____________________ | «24» листопада 2025 р. |

## 10. Додатки
1. `results/aggregated_summary.csv` — агреговані метрики для всіх задач.
2. `results/**/statistical_overview.png` — оглядові графіки для кожного датасету.
3. `results/**/zscore_heatmap.png` та супутні теплові карти.
4. `generated_pipelines/*.py` — згенеровані Gemini-пайплайни для відтворення експериментів.
5. `configs/ablation_config.yaml` — налаштування сценаріїв ablation-аналізу.
