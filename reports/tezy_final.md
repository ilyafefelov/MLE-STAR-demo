# ЕМПІРИЧНА ВАЛІДАЦІЯ ТА АБЛЯЦІЙНЕ ДОСЛІДЖЕННЯ AutoML-ПАЙПЛАЙНІВ

**УДК 004.852:004.896**  
**ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ ТА МАШИННЕ НАВЧАННЯ**

**ЕМПІРИЧНА ВАЛІДАЦІЯ ТА АБЛЯЦІЙНЕ ДОСЛІДЖЕННЯ AutoML-ПАЙПЛАЙНІВ, ЗГЕНЕРОВАНИХ LLM-АГЕНТАМИ: КІЛЬКІСНЕ ПІДТВЕРДЖЕННЯ ГІПОТЕЗИ "НАДМІРНОГО УСКЛАДНЕННЯ" (OVER-ENGINEERING)**

**Автор:** Фефелов Ілля Олександрович, магістрант, Міжрегіональна академія управління персоналом, м. Київ  
**Науковий керівник:** Кавун Сергій Віталійович, д.т.н., професор

---

#### Анотація
Активне застосування великих мовних моделей (LLM) у парадигмі MLE-STAR (Machine Learning Engineering Agent via Search and Targeted Refinement) значно автоматизує створення конвеєрів машинного навчання (AutoML). Однак існує гіпотеза, що LLM-агенти схильні до надмірного ускладнення (Over-engineering), генеруючи надлишкові або навіть шкідливі компоненти. Метою роботи є кількісна перевірка цієї гіпотези шляхом компонентного Ablation-аналізу ML-пайплайнів, згенерованих моделлю Gemini 2.5 Flash Lite.
Дослідження базувалося на серії з $N=20$ повторних запусків для 10 датасетів, використовуючи метрики Accuracy та $R^2$, а також статистичні критерії (ANOVA, t-test, Cohen's d) для оцінки внеску кожного компонента. Результати підтвердили гіпотезу Over-engineering у **10 з 10** проаналізованих випадків, демонструючи, що спрощені конфігурації (наприклад, `minimal` або `no_feature_engineering`) регулярно перевершують "повні" пайплайни, згенеровані LLM, зокрема через невдале ансамблювання та надмірну інженерію ознак. Це обґрунтовує критичну необхідність ітеративної валідації LLM-згенерованого коду.

---

#### Вступ
Стрімке зростання складності систем машинного навчання та їхнє використання у високоризикових доменах, таких як освітній аналіз даних (EDM), вимагає забезпечення інтерпретованості та прозорості (XAI). Ablation-дослідження (вивчення системи шляхом видалення її частин) є потужним науковим методом для досягнення цієї мети, дозволяючи встановити причинно-наслідковий зв'язок і визначити внесок окремого компонента.

В контексті AutoML, інтеграція великих мовних моделей (LLM) прискорила розробку, але створила проблему довіри до згенерованих рішень. LLM-агенти часто схильні до побудови надто складних архітектур, ефективність яких не є очевидною. Наукова новизна роботи полягає у проведенні систематичного компонентного ablation-дослідження пайплайнів, згенерованих Gemini 2.5 Flash Lite. На базі $N=20$ повторних запусків для 10 різнопланових датасетів виконано кількісну перевірку гіпотези Over-engineering, доводячи, що спрощення автоматично згенерованих рішень часто призводить до покращення метрик якості.

#### Методологічна основа дослідження

**2.1 Дизайн Ablation-дослідження**
Дослідження базувалося на порівнянні шести стандартизованих конфігурацій ML-конвеєра: `full` (повний пайплайн, згенерований LLM-агентом), `minimal`, `no_scaling`, `no_feature_engineering`, `no_tuning` та `no_ensemble`. Кожна конфігурація являла собою систематичне видалення одного або декількох компонентів з повного пайплайна.
В ролі LLM-архітектора виступав **Gemini 2.5 Flash Lite**, обраний як оптимальний trade-off між швидкістю та точністю.

**2.2 Метрики та статистичний апарат**
Для оцінки ефективності моделей використовувалися Accuracy (класифікація) та коефіцієнт детермінації $R^2$ (регресія). Ключовим аналітичним інструментом була зміна середньоквадратичної похибки ($\Delta MSE$):

$$ \Delta MSE = MSE_{Ablated} - MSE_{Baseline} $$

*   Велике позитивне $\Delta MSE$ (або падіння Accuracy/$R^2$) підтверджує, що видалений компонент був **критично необхідним**.
*   Незначна або негативна $\Delta MSE$ (або зростання Accuracy/$R^2$) свідчить про **надмірність (Over-engineering)**.

Для забезпечення статистичної валідності та відтворюваності результатів було проведено серію з $N=20$ повторних запусків для кожного експерименту. Це дозволило отримати вузькі 95%-довірчі інтервали (CI), що свідчить про високу стабільність результатів (низьку дисперсію) та робить висновки про перевагу спрощених конфігурацій статистично надійними.

![Statistical Validity](../reports/ci_validity_plot.png)
*Рис. 4. Демонстрація статистичної валідності (California Housing, $N=20$). Вузькі довірчі інтервали вказують на високу стабільність оцінок. Розрив між `minimal` та `full` значно перевищує похибку вимірювання, що підтверджує гіпотезу Over-engineering.*

#### Результати та кількісні докази

**3.1 Кількісне підтвердження гіпотези Over-engineering**
Аналіз результатів підтвердив гіпотезу Over-engineering для всіх 10 проаналізованих датасетів. У кожному випадку найвищий показник якості був досягнутий спрощеною конфігурацією.

**Таблиця 1. Кількісне порівняння спрощених та повних конфігурацій (Вибірка, N=20)**

| Датасет | Найкраща конфігурація | Score | Full Pipeline Score | Різниця ($\Delta$) |
| :--- | :--- | :--- | :--- | :--- |
| **reg_synth_nonlinear** | `minimal` ($R^2$) | **0.851** | 0.443 | +0.408 |
| **reg_california** | `minimal` ($R^2$) | **0.844** | 0.637 | +0.207 |
| **cls_iris** | `no_fe` (Accuracy) | **0.963** | 0.908 | +0.055 |
| **reg_diabetes** | `no_fe` ($R^2$) | **0.469** | 0.400 | +0.069 |

**3.2 Анатомія Over-engineering: Критичні випадки**

**1. "Саботаж ансамблюванням" (California Housing):**
Найбільш драматичний приклад. Повна конфігурація (`full`) включала ансамбль `VotingRegressor` (`LGBM` + `LinearRegression`) та PCA. Ця надлишкова складність знизила якість з $R^2=0.844$ (для `minimal`) до $R^2=0.637$.

![California Housing Overview](../results/reg_california/gemini_live_california-housing-prices_pipeline_wrapper/statistical_overview.png)
*Рис. 1. Статистичний огляд для California Housing. Чітко видно провал повної конфігурації (full) порівняно з minimal.*

**2. Прихована складність (Diabetes):**
Навіть у складніших задачах, таких як Diabetes, спрощена модель (`no_feature_engineering`) перевершила повну на 0.069 пункту $R^2$, що стало очевидним лише при збільшенні вибірки до $N=20$.

![Diabetes Overview](../results/reg_diabetes/gemini_live_diabetes_pipeline_wrapper/statistical_overview.png)
*Рис. 2. Статистичний огляд для Diabetes. Перевага спрощених моделей підтверджується на великій вибірці запусків.*

**3.3 Критична необхідність Preprocessing**
Хоча інженерія ознак часто виявлялася зайвою, масштабування даних (`scaling`) підтвердило свою критичність. Для датасету Breast Cancer відключення масштабування призвело до падіння точності на 10.4%.

![Breast Cancer Overview](../results/cls_breast_cancer/gemini_2.5_flash_lite_breast_cancer_pipeline_wrapper/statistical_overview.png)
*Рис. 3. Вплив компонентів на Breast Cancer. Видно критичне падіння метрик для конфігурації no_scaling.*

#### Висновок
Проведене дослідження надає кількісне підтвердження Гіпотези Надмірного Ускладнення. LLM-агенти схильні до проектування неоптимальної складності, додаючи компоненти (PCA, ансамблювання), які часто погіршують результат. Практичні рекомендації включають впровадження механізму "Early Stopping" для генерації пайплайнів: якщо проста модель (`minimal`) демонструє високий результат, слід уникати подальшого ускладнення архітектури.

#### Список використаних джерел
1. Nam, J., Yoon, J., Chen, J., Shin, J., Arık, S. Ö., & Pfister, T. (2025). *MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement*. arXiv preprint arXiv:2506.15692.
2. Trirat, P., Jeong, W., & Hwang, S. J. (2025). *AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML*. In *Forty-second International Conference on Machine Learning*.
3. Tornede, T., et al. (2025). *A practical evaluation of AutoML tools for binary, multiclass, and regression problems*. *Scientific Reports*, 15, 2149.
4. Kohavi, R. (1995). *A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection*. In *IJCAI* (Vol. 14, No. 2, pp. 1137-1143).
