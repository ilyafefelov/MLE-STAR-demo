#!/usr/bin/env python3
"""
–§–∞–∑–∞ 4: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö (Telecom Churn)
====================================================

–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≥—ñ–ø–æ—Ç–µ–∑–∏ over-engineering –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º—É –ø—Ä–æ–º–∏—Å–ª–æ–≤–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ.

"""

import os
import time
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

from dotenv import load_dotenv
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_TOKEN")

PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
RESULTS_DIR = PROJECT_ROOT / "results" / "real_data_test"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)


def load_telecom_churn():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ç–∞ –≥–æ—Ç—É—î Telecom Churn –¥–∞—Ç–∞—Å–µ—Ç."""
    df = pd.read_csv(DATA_DIR / "telecom_churn.csv")
    
    # –í–∏–¥–∞–ª—è—î–º–æ CustomerID
    df = df.drop('CustomerID', axis=1)
    
    # –ö–æ–¥—É—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ
    cat_cols = ['Gender', 'InternetService', 'Contract', 'PaymentMethod', 'PaperlessBilling']
    num_cols = ['Age', 'Tenure', 'MonthlyCharges', 'TotalCharges']
    
    # Label encoding –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏
    for col in cat_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
    
    X = df.drop('Churn', axis=1).values
    y = df['Churn'].values
    
    return X, y, df.drop('Churn', axis=1).columns.tolist()


def create_simple_pipeline():
    """–ü—Ä–æ—Å—Ç–∏–π pipeline (Simple prompt style)."""
    from sklearn.svm import SVC
    
    return Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler()),
        ('model', SVC(random_state=42, probability=True))
    ])


def create_mle_star_pipeline():
    """–°–∫–ª–∞–¥–Ω–∏–π pipeline (MLE-STAR style –∑ over-engineering)."""
    from sklearn.decomposition import PCA
    from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier
    from sklearn.linear_model import LogisticRegression
    
    # Base estimators
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
    lr = LogisticRegression(max_iter=1000, random_state=42)
    
    # Voting ensemble
    ensemble = VotingClassifier(
        estimators=[('rf', rf), ('gb', gb), ('lr', lr)],
        voting='soft'
    )
    
    return Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler()),
        ('pca', PCA(n_components=0.95)),
        ('model', ensemble)
    ])


def create_minimal_pipeline():
    """–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π pipeline (—Ç—ñ–ª—å–∫–∏ –º–æ–¥–µ–ª—å)."""
    from sklearn.ensemble import GradientBoostingClassifier
    
    return Pipeline([
        ('model', GradientBoostingClassifier(n_estimators=100, random_state=42))
    ])


def create_optimal_pipeline():
    """–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π pipeline (–Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞—à–∏—Ö –≤–∏—Å–Ω–æ–≤–∫—ñ–≤)."""
    from sklearn.ensemble import HistGradientBoostingClassifier
    
    return Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler()),
        ('model', HistGradientBoostingClassifier(random_state=42))
    ])


def evaluate_pipeline(pipeline, X, y, name, n_runs=5):
    """–û—Ü—ñ–Ω—é—î pipeline."""
    scores = []
    f1_scores = []
    
    for run in range(n_runs):
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run)
        
        # Accuracy
        acc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)
        scores.append(np.mean(acc_scores))
        
        # F1
        f1 = cross_val_score(pipeline, X, y, cv=cv, scoring='f1', n_jobs=-1)
        f1_scores.append(np.mean(f1))
    
    return {
        'name': name,
        'accuracy_mean': np.mean(scores),
        'accuracy_std': np.std(scores),
        'f1_mean': np.mean(f1_scores),
        'f1_std': np.std(f1_scores),
        'n_runs': n_runs,
    }


def run_phase4_experiment():
    """–ó–∞–ø—É—Å–∫–∞—î –§–∞–∑—É 4: —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö."""
    print("=" * 70)
    print("üìä –§–ê–ó–ê 4: –¢–ï–°–¢–£–í–ê–ù–ù–Ø –ù–ê –†–ï–ê–õ–¨–ù–ò–• –î–ê–ù–ò–• (TELECOM CHURN)")
    print("=" * 70)
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
    print("\nüìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é Telecom Churn –¥–∞—Ç–∞—Å–µ—Ç...")
    X, y, feature_names = load_telecom_churn()
    print(f"   ‚Ä¢ –ó—Ä–∞–∑–∫—ñ–≤: {X.shape[0]}")
    print(f"   ‚Ä¢ –û–∑–Ω–∞–∫: {X.shape[1]}")
    print(f"   ‚Ä¢ –ö–ª–∞—Å–∏: {np.unique(y)} (Churn: {np.sum(y)}, No Churn: {len(y) - np.sum(y)})")
    
    # –¢–µ—Å—Ç—É—î–º–æ —Ä—ñ–∑–Ω—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    pipelines = {
        'Simple (SVC)': create_simple_pipeline(),
        'MLE-STAR (VotingClassifier + PCA)': create_mle_star_pipeline(),
        'Minimal (GradientBoosting only)': create_minimal_pipeline(),
        'Optimal (Scaler + HistGB)': create_optimal_pipeline(),
    }
    
    results = []
    
    print("\nüß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π...")
    for name, pipeline in pipelines.items():
        print(f"\n   ‚Üí {name}")
        start = time.time()
        result = evaluate_pipeline(pipeline, X, y, name)
        elapsed = time.time() - start
        result['time_sec'] = elapsed
        results.append(result)
        print(f"     Accuracy: {result['accuracy_mean']:.4f} ¬± {result['accuracy_std']:.4f}")
        print(f"     F1-score: {result['f1_mean']:.4f} ¬± {result['f1_std']:.4f}")
        print(f"     –ß–∞—Å: {elapsed:.1f}—Å")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    df = pd.DataFrame(results)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_path = RESULTS_DIR / f"telecom_churn_experiment_{timestamp}.csv"
    df.to_csv(csv_path, index=False)
    
    # –í–∏–≤–æ–¥–∏–º–æ –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é
    print("\n" + "=" * 70)
    print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–ò –§–ê–ó–ò 4")
    print("=" * 70)
    
    df_sorted = df.sort_values('accuracy_mean', ascending=False)
    print("\n–†–µ–π—Ç–∏–Ω–≥ –ø–æ Accuracy:")
    for i, row in df_sorted.iterrows():
        print(f"   {row['accuracy_mean']:.4f} ¬± {row['accuracy_std']:.4f} | {row['name']}")
    
    print("\n–†–µ–π—Ç–∏–Ω–≥ –ø–æ F1-score:")
    df_f1 = df.sort_values('f1_mean', ascending=False)
    for i, row in df_f1.iterrows():
        print(f"   {row['f1_mean']:.4f} ¬± {row['f1_std']:.4f} | {row['name']}")
    
    # –ê–Ω–∞–ª—ñ–∑
    best_acc = df_sorted.iloc[0]
    mle_star = df[df['name'].str.contains('MLE-STAR')].iloc[0]
    
    print("\n" + "=" * 70)
    print("üìä –ê–ù–ê–õ–Ü–ó")
    print("=" * 70)
    
    if best_acc['name'] != mle_star['name']:
        delta = best_acc['accuracy_mean'] - mle_star['accuracy_mean']
        print(f"\n‚úÖ –ì–Ü–ü–û–¢–ï–ó–ê –ü–Ü–î–¢–í–ï–†–î–ñ–ï–ù–ê –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö!")
        print(f"   ‚Ä¢ –ü–µ—Ä–µ–º–æ–∂–µ—Ü—å: {best_acc['name']}")
        print(f"   ‚Ä¢ MLE-STAR: {mle_star['accuracy_mean']:.4f}")
        print(f"   ‚Ä¢ –†—ñ–∑–Ω–∏—Ü—è: +{delta:.4f} ({delta*100:.2f}%)")
        print(f"\n   Over-engineering (VotingClassifier + PCA) –ø—Ä–æ–≥—Ä–∞—î –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö!")
    else:
        print(f"\n‚ö†Ô∏è MLE-STAR –≤–∏—è–≤–∏–≤—Å—è –Ω–∞–π–∫—Ä–∞—â–∏–º –Ω–∞ —Ü—å–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ")
    
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {csv_path}")
    
    return df


if __name__ == "__main__":
    run_phase4_experiment()
