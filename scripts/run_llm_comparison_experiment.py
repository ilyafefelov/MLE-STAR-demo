#!/usr/bin/env python3
"""
Ð•ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ Ð¿Ð¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð½Ñ LLM: Simple Prompt vs MLE-STAR vs GPT-4o
================================================================

ÐœÐµÑ‚Ð°: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸, Ñ‡Ð¸ Ð³Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð° over-engineering Ð·Ð°Ð»ÐµÐ¶Ð¸Ñ‚ÑŒ Ð²Ñ–Ð´:
1. Ð¡ÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ– Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ (simple vs MLE-STAR)
2. Ð’Ð¸Ð±Ð¾Ñ€Ñƒ LLM (Gemini vs GPT-4o)

"""

import os
import sys
import json
import time
import re
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris, load_breast_cancer, fetch_california_housing
from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold
from sklearn.pipeline import Pipeline

# Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ API ÐºÐ»ÑŽÑ‡Ñ–Ð²
from dotenv import load_dotenv
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—
PROJECT_ROOT = Path(__file__).parent.parent
RESULTS_DIR = PROJECT_ROOT / "results" / "llm_comparison"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)


# ============================================================================
# ÐŸÐ ÐžÐœÐŸÐ¢Ð˜
# ============================================================================

SIMPLE_PROMPT_TEMPLATE = """
Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ sklearn Pipeline Ð´Ð»Ñ {task_type} Ð½Ð° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ– {dataset_name}.

Ð”Ð°Ð½Ñ–: {n_samples} Ð·Ñ€Ð°Ð·ÐºÑ–Ð², {n_features} Ð¾Ð·Ð½Ð°Ðº{class_info}.
Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð”Ð°Ð½Ñ– Ð¿ÐµÑ€ÐµÐ´Ð°ÑŽÑ‚ÑŒÑÑ ÑÐº numpy array (X, y), ÐÐ• pandas DataFrame!

ÐŸÐ¾Ð²ÐµÑ€Ð½Ð¸ Ð¢Ð†Ð›Ð¬ÐšÐ˜ Python ÐºÐ¾Ð´:
- Ð£ÑÑ– Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸ ÐÐ ÐŸÐžÐ§ÐÐ¢ÐšÐ£ Ñ„Ð°Ð¹Ð»Ñƒ (Ð¿ÐµÑ€ÐµÐ´ def)
- ÐÐ• Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ type hints Ñƒ ÑÐ¸Ð³Ð½Ð°Ñ‚ÑƒÑ€Ñ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—
- ÐŸÑ€Ð¾ÑÑ‚Ð¸Ð¹ pipeline: StandardScaler + Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 2-3 ÐºÑ€Ð¾ÐºÐ¸)

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC  # Ð°Ð±Ð¾ Ñ–Ð½ÑˆÐ° Ð¼Ð¾Ð´ÐµÐ»ÑŒ

def build_full_pipeline(random_state=42):
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('model', SVC(random_state=random_state))
    ])
    return pipeline
```
"""

MLE_STAR_PROMPT_TEMPLATE = """
Ð¢Ð¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Machine Learning Engineer. Ð“ÐµÐ½ÐµÑ€ÑƒÐ¹ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ scikit-learn ML pipeline.

Ð”ÐÐ¢ÐÐ¡Ð•Ð¢: {dataset_name}
- Ð—Ñ€Ð°Ð·ÐºÑ–Ð²: {n_samples}
- ÐžÐ·Ð½Ð°Ðº: {n_features}
{class_info}

Ð’Ð˜ÐœÐžÐ“Ð˜:
1. Pipeline Ð¼Ð°Ñ” Ð¼Ñ–ÑÑ‚Ð¸Ñ‚Ð¸:
   - preprocessor: SimpleImputer + StandardScaler
   - feature_engineering: PCA Ð°Ð±Ð¾ PolynomialFeatures
   - model: ÐžÐ±ÐµÑ€Ð¸ ÐÐÐ™ÐšÐ ÐÐ©Ð£ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (RandomForest, GradientBoosting, SVM, etc.)

2. Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŽÐ²Ð°Ð½Ð½Ñ (VotingClassifier/VotingRegressor) ÑÐºÑ‰Ð¾ Ñ†Ðµ Ð¿Ð¾ÐºÑ€Ð°Ñ‰Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚

3. ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ¹ Ð³Ñ–Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñƒ

4. Ð”Ð¾Ð´Ð°Ð¹ ÐºÐ¾Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ñ– Ð· Ð¾Ð±Ò‘Ñ€ÑƒÐ½Ñ‚ÑƒÐ²Ð°Ð½Ð½ÑÐ¼ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ

5. Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð”Ð°Ð½Ñ– Ð¿ÐµÑ€ÐµÐ´Ð°ÑŽÑ‚ÑŒÑÑ ÑÐº numpy array (X, y), ÐÐ• DataFrame. 
   ÐÐ• Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ ColumnTransformer Ð· Ñ–Ð¼ÐµÐ½Ð°Ð¼Ð¸ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº!
   ÐŸÑ€Ð°Ñ†ÑŽÐ¹ Ð· ÑƒÑÑ–Ð¼Ð° Ð¾Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸ Ð¾Ð´Ñ€Ð°Ð·Ñƒ (StandardScaler Ð´Ð»Ñ Ð²ÑÑ–Ñ…).

6. Ð—ÐÐ‘ÐžÐ ÐžÐÐ•ÐÐž: GridSearchCV, RandomizedSearchCV (Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð¿Ð¾Ð²Ñ–Ð»ÑŒÐ½Ð¾)
   Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ Ñ„Ñ–ÐºÑÐ¾Ð²Ð°Ð½Ñ– Ð³Ñ–Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸.

Ð¤ÐžÐ ÐœÐÐ¢ Ð’Ð†Ð”ÐŸÐžÐ’Ð†Ð”Ð† - Ð¢Ð†Ð›Ð¬ÐšÐ˜ ÐšÐžÐ”:
- Ð£ÑÑ– Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸ ÐÐ ÐŸÐžÐ§ÐÐ¢ÐšÐ£ Ñ„Ð°Ð¹Ð»Ñƒ
- ÐÐ• Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ type hints (-> Pipeline)
- Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” sklearn.pipeline.Pipeline

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
# ... Ñ–Ð½ÑˆÑ– Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸

def build_full_pipeline(random_state=42):
    # Ñ‚Ð²Ñ–Ð¹ ÐºÐ¾Ð´
    return pipeline
```
"""


def get_dataset_info(dataset_name: str) -> Dict[str, Any]:
    """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ” Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ– Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Ð¹Ð¾Ð³Ð¾ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ."""
    if dataset_name == "iris":
        data = load_iris()
        task_type = "ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—"
        class_info = f", {len(np.unique(data.target))} ÐºÐ»Ð°ÑÑ–Ð²"
        is_classification = True
    elif dataset_name == "breast_cancer":
        data = load_breast_cancer()
        task_type = "ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—"
        class_info = f", {len(np.unique(data.target))} ÐºÐ»Ð°ÑÑ–Ð²"
        is_classification = True
    elif dataset_name == "california_housing":
        data = fetch_california_housing()
        task_type = "Ñ€ÐµÐ³Ñ€ÐµÑÑ–Ñ—"
        class_info = ""
        is_classification = False
    else:
        raise ValueError(f"ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚: {dataset_name}")
    
    return {
        "X": data.data,
        "y": data.target,
        "n_samples": data.data.shape[0],
        "n_features": data.data.shape[1],
        "task_type": task_type,
        "class_info": class_info,
        "is_classification": is_classification,
        "dataset_name": dataset_name,
    }


def format_prompt(template: str, info: Dict[str, Any]) -> str:
    """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÑ” Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð· Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ”ÑŽ Ð¿Ñ€Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚."""
    return template.format(
        dataset_name=info["dataset_name"],
        n_samples=info["n_samples"],
        n_features=info["n_features"],
        task_type=info["task_type"],
        class_info=info["class_info"],
    )


# ============================================================================
# LLM API Ð’Ð˜ÐšÐ›Ð˜ÐšÐ˜
# ============================================================================

def call_gemini(prompt: str, model: str = "gemini-2.0-flash") -> str:
    """Ð’Ð¸ÐºÐ»Ð¸Ðº Gemini API."""
    import google.generativeai as genai
    
    genai.configure(api_key=GEMINI_API_KEY)
    model_obj = genai.GenerativeModel(model)
    
    response = model_obj.generate_content(prompt)
    return response.text


def call_openai(prompt: str, model: str = "gpt-4o") -> str:
    """Ð’Ð¸ÐºÐ»Ð¸Ðº OpenAI API."""
    from openai import OpenAI
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "Ð¢Ð¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Machine Learning Engineer. Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ Python ÐºÐ¾Ð´Ð¾Ð¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
    )
    return response.choices[0].message.content


def extract_code(response: str) -> str:
    """Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ” Python ÐºÐ¾Ð´ Ð· Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– LLM."""
    # Ð¨ÑƒÐºÐ°Ñ”Ð¼Ð¾ ÐºÐ¾Ð´ Ð¼Ñ–Ð¶ ```python Ñ– ```
    pattern = r"```python\s*(.*?)\s*```"
    matches = re.findall(pattern, response, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    # Ð¯ÐºÑ‰Ð¾ Ð½ÐµÐ¼Ð°Ñ” Ð¼Ð°Ñ€ÐºÐµÑ€Ñ–Ð², ÑˆÑƒÐºÐ°Ñ”Ð¼Ð¾ def build_full_pipeline
    if "def build_full_pipeline" in response:
        start = response.find("def build_full_pipeline")
        # Ð—Ð½Ð°Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ ÐºÑ–Ð½ÐµÑ†ÑŒ Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— (Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ def Ð°Ð±Ð¾ ÐºÑ–Ð½ÐµÑ†ÑŒ)
        end = response.find("\ndef ", start + 1)
        if end == -1:
            end = len(response)
        return response[start:end].strip()
    
    return response


def execute_code_and_get_pipeline(code: str, random_state: int = 42, timeout_sec: int = 30) -> Optional[Pipeline]:
    """Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ” ÐºÐ¾Ð´ Ñ– Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Pipeline Ð· timeout."""
    import signal
    import threading
    
    # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ namespace Ð´Ð»Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ
    namespace = {}
    result = {"pipeline": None, "error": None}
    
    def run_code():
        try:
            exec(code, namespace)
            
            if "build_full_pipeline" not in namespace:
                result["error"] = "Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ build_full_pipeline Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð°"
                return
            
            result["pipeline"] = namespace["build_full_pipeline"](random_state=random_state)
        except Exception as e:
            result["error"] = str(e)
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ Ð² Ð¾ÐºÑ€ÐµÐ¼Ð¾Ð¼Ñƒ Ð¿Ð¾Ñ‚Ð¾Ñ†Ñ– Ð· timeout
    thread = threading.Thread(target=run_code)
    thread.start()
    thread.join(timeout=timeout_sec)
    
    if thread.is_alive():
        print(f"  âš ï¸ Timeout ({timeout_sec}Ñ) - ÐºÐ¾Ð´ Ð²Ð¸ÐºÐ¾Ð½ÑƒÑ”Ñ‚ÑŒÑÑ Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð´Ð¾Ð²Ð³Ð¾")
        return None
    
    if result["error"]:
        print(f"  âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ ÐºÐ¾Ð´Ñƒ: {result['error']}")
        return None
    
    return result["pipeline"]


def evaluate_pipeline(
    pipeline: Pipeline, 
    X: np.ndarray, 
    y: np.ndarray, 
    is_classification: bool,
    n_runs: int = 5,
) -> Dict[str, float]:
    """ÐžÑ†Ñ–Ð½ÑŽÑ” pipeline Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ cross-validation."""
    scores = []
    
    for run in range(n_runs):
        seed = 42 + run
        
        if is_classification:
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
            scoring = "accuracy"
        else:
            cv = KFold(n_splits=5, shuffle=True, random_state=seed)
            scoring = "r2"
        
        try:
            cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1)
            scores.append(np.mean(cv_scores))
        except Exception as e:
            print(f"  âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° CV (run {run}): {e}")
            continue
    
    if not scores:
        return {"mean": 0.0, "std": 0.0, "n_runs": 0}
    
    return {
        "mean": np.mean(scores),
        "std": np.std(scores),
        "n_runs": len(scores),
    }


# ============================================================================
# Ð“ÐžÐ›ÐžÐ’ÐÐ˜Ð™ Ð•ÐšÐ¡ÐŸÐ•Ð Ð˜ÐœÐ•ÐÐ¢
# ============================================================================

def run_single_experiment(
    dataset_name: str,
    prompt_type: str,  # "simple" Ð°Ð±Ð¾ "mle_star"
    llm_type: str,     # "gemini" Ð°Ð±Ð¾ "gpt4o"
    n_runs: int = 5,
) -> Dict[str, Any]:
    """Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ” Ð¾Ð´Ð¸Ð½ ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚."""
    print(f"\n{'='*60}")
    print(f"Ð”Ð°Ñ‚Ð°ÑÐµÑ‚: {dataset_name} | ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: {prompt_type} | LLM: {llm_type}")
    print(f"{'='*60}")
    
    # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚
    info = get_dataset_info(dataset_name)
    
    # Ð’Ð¸Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ
    if prompt_type == "simple":
        template = SIMPLE_PROMPT_TEMPLATE
    else:
        template = MLE_STAR_PROMPT_TEMPLATE
    
    prompt = format_prompt(template, info)
    
    # Ð’Ð¸ÐºÐ»Ð¸Ðº LLM
    print(f"ðŸ“¤ Ð’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ Ð·Ð°Ð¿Ð¸Ñ‚ Ð´Ð¾ {llm_type}...")
    start_time = time.time()
    
    try:
        if llm_type == "gemini":
            response = call_gemini(prompt)
        else:
            response = call_openai(prompt)
        
        api_time = time.time() - start_time
        print(f"âœ… Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð¾ Ð·Ð° {api_time:.1f}Ñ")
        
    except Exception as e:
        print(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° API: {e}")
        return {
            "dataset": dataset_name,
            "prompt_type": prompt_type,
            "llm_type": llm_type,
            "status": "api_error",
            "error": str(e),
        }
    
    # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð´
    code = extract_code(response)
    
    # Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð´
    print("ðŸ”§ Ð‘ÑƒÐ´ÑƒÑŽ pipeline...")
    pipeline = execute_code_and_get_pipeline(code)
    
    if pipeline is None:
        return {
            "dataset": dataset_name,
            "prompt_type": prompt_type,
            "llm_type": llm_type,
            "status": "code_error",
            "code": code,
            "response": response[:500],
        }
    
    # ÐžÑ†Ñ–Ð½ÑŽÑ”Ð¼Ð¾
    print(f"ðŸ“Š ÐžÑ†Ñ–Ð½ÑŽÑŽ pipeline ({n_runs} Ð·Ð°Ð¿ÑƒÑÐºÑ–Ð²)...")
    metrics = evaluate_pipeline(
        pipeline, 
        info["X"], 
        info["y"], 
        info["is_classification"],
        n_runs=n_runs,
    )
    
    print(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {metrics['mean']:.4f} Â± {metrics['std']:.4f}")
    
    # ÐÐ½Ð°Ð»Ñ–Ð· ÑÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ– pipeline
    pipeline_info = analyze_pipeline_complexity(pipeline)
    
    return {
        "dataset": dataset_name,
        "prompt_type": prompt_type,
        "llm_type": llm_type,
        "status": "success",
        "score_mean": metrics["mean"],
        "score_std": metrics["std"],
        "n_runs": metrics["n_runs"],
        "api_time_sec": api_time,
        **pipeline_info,
    }


def analyze_pipeline_complexity(pipeline: Pipeline) -> Dict[str, Any]:
    """ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑ” ÑÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ pipeline."""
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    from sklearn.ensemble import VotingClassifier, VotingRegressor, RandomForestClassifier
    
    steps = pipeline.steps
    n_steps = len(steps)
    
    # Ð’Ð¸Ð·Ð½Ð°Ñ‡Ð°Ñ”Ð¼Ð¾ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸
    has_scaler = False
    has_pca = False
    has_ensemble = False
    model_type = "unknown"
    
    for name, est in steps:
        if isinstance(est, Pipeline):
            for _, nested in est.steps:
                if isinstance(nested, StandardScaler):
                    has_scaler = True
                if isinstance(nested, PCA):
                    has_pca = True
        else:
            if isinstance(est, StandardScaler):
                has_scaler = True
            if isinstance(est, PCA):
                has_pca = True
            if isinstance(est, (VotingClassifier, VotingRegressor)):
                has_ensemble = True
            # ÐžÑÑ‚Ð°Ð½Ð½Ñ–Ð¹ ÐºÑ€Ð¾Ðº - Ð¼Ð¾Ð´ÐµÐ»ÑŒ
            if name in ["model", "estimator", "clf", "regressor"] or steps[-1] == (name, est):
                model_type = type(est).__name__
    
    return {
        "n_steps": n_steps,
        "has_scaler": has_scaler,
        "has_pca": has_pca,
        "has_ensemble": has_ensemble,
        "model_type": model_type,
    }


def run_full_experiment():
    """Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ” Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚."""
    print("\n" + "="*70)
    print("ðŸ§ª Ð•ÐšÐ¡ÐŸÐ•Ð Ð˜ÐœÐ•ÐÐ¢: ÐŸÐžÐ Ð†Ð’ÐÐ¯ÐÐÐ¯ LLM Ð¢Ð Ð¢Ð˜ÐŸÐ†Ð’ ÐŸÐ ÐžÐœÐŸÐ¢Ð†Ð’")
    print("="*70)
    
    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ð½Ð°ÑÐ²Ð½Ñ–ÑÑ‚ÑŒ API ÐºÐ»ÑŽÑ‡Ñ–Ð²
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_TOKEN Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾!")
        return
    if not OPENAI_API_KEY:
        print("âš ï¸ OPENAI_API_KEY Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ - GPT-4o Ð±ÑƒÐ´Ðµ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾")
    
    datasets = ["iris", "breast_cancer", "california_housing"]
    prompt_types = ["simple", "mle_star"]
    llm_types = ["gemini"]
    if OPENAI_API_KEY:
        llm_types.append("gpt4o")
    
    results = []
    
    for dataset in datasets:
        for prompt_type in prompt_types:
            for llm_type in llm_types:
                result = run_single_experiment(
                    dataset_name=dataset,
                    prompt_type=prompt_type,
                    llm_type=llm_type,
                    n_runs=5,
                )
                results.append(result)
                
                # ÐÐµÐ²ÐµÐ»Ð¸ÐºÐ° Ð¿Ð°ÑƒÐ·Ð° Ð¼Ñ–Ð¶ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð¼Ð¸
                time.sleep(1)
    
    # Ð—Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ð¼Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸
    df = pd.DataFrame(results)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    csv_path = RESULTS_DIR / f"llm_comparison_{timestamp}.csv"
    df.to_csv(csv_path, index=False)
    print(f"\nðŸ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾: {csv_path}")
    
    # Ð’Ð¸Ð²Ð¾Ð´Ð¸Ð¼Ð¾ Ð·Ð²ÐµÐ´ÐµÐ½Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÑŽ
    print("\n" + "="*70)
    print("ðŸ“Š Ð—Ð’Ð•Ð”Ð•ÐÐ† Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð˜")
    print("="*70)
    
    success_df = df[df["status"] == "success"]
    if len(success_df) > 0:
        summary = success_df.groupby(["dataset", "prompt_type", "llm_type"]).agg({
            "score_mean": "mean",
            "score_std": "mean",
            "n_steps": "mean",
            "has_pca": "mean",
            "has_ensemble": "mean",
        }).round(4)
        print(summary.to_string())
    
    return df


if __name__ == "__main__":
    run_full_experiment()
